# Neural Network Basics

[TOC]



## Res


## Intro


## Ref
[What Is the Necessity of Bias in Neural Networks?]: https://www.turing.com/kb/necessity-of-bias-in-neural-networks#components-in-artificial-neural-networks

Components in artificial neural networks:
1.  **Inputs:** They’re usually represented as features of a dataset which are passed on to a neural network to make predictions.
2.  **Weights:** These are the real values associated with the features. They are significant as they tell the importance of each feature which is passed as an input to the [artificial neural network](https://www.turing.com/kb/importance-of-artificial-neural-networks-in-artificial-intelligence).
3.  **Bias:** Bias in a neural network is required to shift the activation function across the plane either towards the left or the right. We will cover it in more detail later.
4.  **Summation function:** It is defined as the function which sums up the product of the weight and the features with bias.
5.  **Activation function:** It is required to add non-linearity to the neural network model

# Memory Protections & Mitigations

[TOC]



## Res
### Related Topics
â†— [Win Memory Protection Mechanism](../../Operating%20System%20Security/ğŸªŸ%20Windows%20Security/Windows%20Security%20Mechanisms/ğŸ“Œ%20Win%20Memory%20Protection%20Mechanism/Win%20Memory%20Protection%20Mechanism.md)
â†— [Linux Memory Protection Mechanism](../../Operating%20System%20Security/ğŸ%20Linux%20Security/Linux%20Kernel%20Security%20Mechanisms/ğŸ“Œ%20Linux%20Memory%20Protection%20Mechanism/Linux%20Memory%20Protection%20Mechanism.md)

â†— [Programming Methodology and Languages](../../../../ğŸ”‘%20CS%20Core/ğŸ‘©â€ğŸ’»%20Programming%20Methodology%20and%20Languages/Programming%20Methodology%20and%20Languages.md)
â†— [Compilation & Program Loading Tools](../../../../ğŸ”‘%20CS%20Core/ğŸ‘©â€ğŸ’»%20Programming%20Methodology%20and%20Languages/ğŸ› ï¸%20Programming%20Tools%20Chain/Compilation%20&%20Program%20Loading%20Tools/Compilation%20&%20Program%20Loading%20Tools.md)
â†— [Operating System Security](../../Operating%20System%20Security/Operating%20System%20Security.md)


### Other Resources
ğŸ“– https://textbook.cs161.org/memory-safety/mitigations.html



## ğŸ¯ How to Mitigate /Eliminate Memory Vulnerabilities?
> ğŸ”— https://textbook.cs161.org/memory-safety/mitigations.html

> Since most OS kernels are written in C/C++, which relied by all above applications, we cannot really eliminate memory vulnerabilities because eventually all codes are running in c compiled instructions. However, by principle of "defense-in-depth", we can ensure we don't write programs that has memory safety issues using multiple methods, including memory-safety languages, which fundamentally guarantee the we produce memory safety code (which will also eventually implemented in memory-unsafe language, C, but memory-safety languages like java make sue our ultimate memory-unsafe C language version of code is safe ğŸ¥º). Except using memory-safety languages, all other means do not eliminate such insecurity, these includes writing memory safety codes by programmer (but they still would make mistakes), using software testing tools (but they don't guarantee 100% coverage), mitigating specific exploits, and so on.
> ![](../../../../../../../Assets/Pics/Pasted%20image%2020240915011047.png)


### 1. Memory-Safety Languages (SDK/Library)
Some modern languages are designed to be intrinsically memory-safe, no matter what the programmer does. Java, Python, Go, Rust, Swift, and many other programming languages include a combination of compile-time and runtime checks that prevent memory errors from occurring. Using a memory safe language is theÂ _only_Â way to stop 100% of memory safety vulnerabilities. In an ideal world, everyone would program in memory-safe languages and buffer overflow vulnerabilities would no longer exist. However, because of legacy code and perceived[1](https://textbook.cs161.org/memory-safety/mitigations.html#fn:1)Â performance concerns, memory-unsafe languages such as C are still prevalent today.


### 2. Memory-Safety Codes /Defensive Programming (Programmer)
> â†— [Program Debugging & Defensive Programming](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/Program%20Debugging%20&%20Defensive%20Programming.md)

One way to ensure memory safety is to carefully reason about memory accesses in your code, by defining pre-conditions and post-conditions for every function you write and using invariants to prove that these conditions are satisfied. Although it is a good skill to have, this process is painstakingly tedious and rarely used in practice, so it is no longer in scope for this class. 

> If youâ€™d like to learn more, see this lecture from David Wagner:Â [video](https://www.youtube.com/watch?v=d8UGf6aWiQI),Â [slides](https://su20.cs161.org/lectures/4/lec04_optional.pdf).

Another example of defending against memory safety vulnerabilities is writing memory-safe code through defensive programming and using safe libraries. 
- **Defensive programming** is very similar to defining pre and post conditions for every written function, wherein you always add checks in your code just in case something could go wrong. For example, you would always check that a pointer is not null before dereferencing it, even if you are sure that the pointer is always going to be valid. However, as mentioned earlier, this relies a lot on programmer discipline and is very tedious to properly implement.
- As such, a more common method is to use **safe libraries**, which, in turn, use functions that check bounds so you donâ€™t have to. For example, 
	- usingÂ `fgets`Â instead ofÂ `gets`,Â 
	- `strncpy`Â orÂ `strlcpy`Â instead ofÂ `strcpy`,
	- `snprintf`Â instead ofÂ `sprintf`
- **Reason carefully** about your code
	- When writing code, define a set of preconditions, postconditions, and invariants that must be satisfied for the code to be memory-safe
	- Very tedious and rarely used in practice,  


### 3. Software Analyzing /Testing
Yet another way to defend your code is to use tools to analyze and patch insecure code. 
- Utilizing **run-time checks** that do automatic bound-checking, for example is an excellent way to help your code stay safe. If your check fails, you can direct it towards a controlled crash, ensuring that the attacker does not succeed. 
	- Monitor code for run-time misbehavior
		- Example: Look for illegal calling sequences
		- Example: Your code never calls execve, but you notice that your code is executing execve
		- Probably too late by the time you detect it
	- Contain potential damage
		- Example: Run system components in sandboxes or virtual machines (VMs)
		- Think about privilege separation 
- You can also probe your own system for vulnerabilities, by subjecting your code to **thorough software tests**. Though it is pretty difficult to know whether you have tested your code â€œenoughâ€ to deem it safe, there are several code-coverage tools that can help you out.
	- Bug-finding tools
		- Excellent resource, as long as there arenâ€™t too many false alarms
		- â†— [Valgrind](../../../../ğŸ”‘%20CS%20Core/ğŸ‘©â€ğŸ’»%20Programming%20Methodology%20and%20Languages/ğŸ› ï¸%20Programming%20Tools%20Chain/Debuggers%20&%20Disassemblers%20&%20Decompilers/Valgrind.md) (to detect memory leaks)
		- â†— [Fuzzing (Fuzz Testing)](../../../ğŸ°%20Cybersecurity%20Basics%20&%20InfoSec/ğŸ¦%20Software%20Security/ğŸ’%20Software%20Vulnerability%20&%20Weakness/Vulnerability%20Disclosureï¼ˆæ¼æ´æŒ–æ˜ï¼‰/Fuzzing%20(Fuzz%20Testing)/Fuzzing%20(Fuzz%20Testing).md), or testing with random inputs, testing corner cases
	- Code review
		- Have someone look over your code for memory safety errors. Can be very effectiveâ€¦ but also expensive
	- Vulnerability scanning
		- Probe your systems for known flaws
	- Penetration testing (â€œpen-testingâ€)
		- Pay someone to break into your system



## ğŸ¯ 4. Exploit Mitigations /Code Hardening Defenses (Our Topics Here ğŸ¥º)
### ğŸ“Œ Synergistic Protection & Combining Mitigations 
We can use multiple mitigations together to force the attacker to find multiple vulnerabilities to exploit the program; this is a process known asÂ **synergistic protection**, where one mitigation helps strengthen another mitigation. For example, combining ASLR and non-executable pages results in an attacker not being able to write their own shellcode, because of non-executable pages, and not being able to use existing code in memory, because they donâ€™t know the addresses of that code (ASLR). Thus, to defeat ASLR and non-executable pages, the attacker needs to find two vulnerabilities. First, they need to find a way to leak memory and reveal the address location (to defeat ASLR). Next, they need to find a way to write to memory and write an ROP chain (to defeat non-executable pages).


### Non-executable Pages
> â†— [Return-to-libc Attack](../Memory%20Threats%20&%20Attacks/Stack%20Attack/Return-to-libc%20&%20ROP/Return-to-libc%20Attack.md)
> â†— [ROP (Return-Oriented Programming)](../Memory%20Threats%20&%20Attacks/Stack%20Attack/Return-to-libc%20&%20ROP/ROP%20(Return-Oriented%20Programming).md)


### Stack Canaries
> In reality, stack canaries are **usually guaranteed to contain a null byte (usually as the first byte)**. This lets the canary defend against string-based memory safety exploits, such as vulnerable calls toÂ `strcpy`Â that read or write values from the stack until they encounter a null byte. The null byte in the canary stops theÂ `strcpy`Â call before it can copy past the canary and affect the rip.
#### Subverting Stack Canaries
Stack canaries make buffer overflow attacks harder for an attacker, but they do not defend programs against all buffer overflow attacks. There are many exploits that the stack canary cannot detect:
- Stack canaries canâ€™t defend against attacks outside of the stack. For example, stack canaries do nothing to protect vulnerable heap memory.
- Stack canaries donâ€™t stop an attacker from overwriting other local variables. Consider theÂ `authenticated` example from the previous section. An attacker overflowing a buffer to overwrite theÂ `authenticated` variable never actually changes the canary value.
- Some exploits can write to non-consecutive parts of memory. For example, format string vulnerabilities let an attacker write directly to the rip without having to overwrite everything between a local variable and the rip. This lets the attacker write "around" the canary and overwrite the rip without changing the value of the canary.

Additionally, there are several techniques for defeating the stack canary. These usually involve the attacker modifying their exploit to overwrite the canary with its original value. When the program returns, it will see that the canary is unchanged, and the program wonâ€™t detect the exploit.

**Guess the canary**: On a 32-bit architecture, the stack canary usually only has 24 bits of entropy (randomness), because one of the four bytes is always a null byte. If the attacker runs the program with an exploit, there is a roughly 1 inÂ 224Â chance that the the value the attacker is overwriting the canary with matches the actual canary value. Although the probability of success is low on one try, the attacker can simply run the programÂ 224Â times and successfully exploit the program at least once with high probability.

Depending on the setting, it may be easy or hard to run a program and inject an exploitÂ 224Â times. If each try takes 1 second, the attacker would need to try for over 100 days before they succeed. If the program is configured to take exponentially longer to run each time the attacker crashes it, the attacker might never be able to try enough times to succeed. However, if the attacker can try thousands of times per second, then the attacker will probably succeed in just a few hours.

On a 64-bit architecture, the stack canary has 56 bits of randomness, so it is significantly harder to guess the canary value. Even at 1,000 tries per second, an attacker would need over 2 million years on average to guess the canary!

**Leak the canary**: Sometimes the program has a vulnerability that allows the attacker to read parts of memory. For example, a format string vulnerability might let the attacker print out values from the stack. An attacker could use this vulnerability to leak the value of the canary, write it down, and then inject an exploit that overwrites the canary with its leaked value. All of this can happen within a single run of the program, so the canary value doesnâ€™t change on program restart.


### Pointer Authentication
> â†— [Message Authentication (æŠ¥æ–‡é‰´åˆ«ï¼Œæ¶ˆæ¯é‰´åˆ«)](../../../ğŸš¬%20Cryptology%20&%20Secure%20Communication/Message%20Authentication%20(æŠ¥æ–‡é‰´åˆ«ï¼Œæ¶ˆæ¯é‰´åˆ«)/Message%20Authentication%20(æŠ¥æ–‡é‰´åˆ«ï¼Œæ¶ˆæ¯é‰´åˆ«).md)

#### Subverting Pointer Authentication
Using a different PAC for every address makes this defense extremely strong. An attacker who can write to random parts of memory can defeat the stack canary, but cannot easily defeat pointer authentication: they could try to leave the PAC untouched, but because theyâ€™ve changed the address, the old secret value will no longer check out. The CPU will runÂ fÂ on the attacker-generated address, and the output will be different from the old secret value (which was generated by runningÂ fÂ on the original address). The attacker also cannot generate the correct secret value for their malicious address, because they donâ€™t know what the secret key is. Finally, an attacker could try to leak some addresses and secret values from memory, but knowing the PACs doesnâ€™t help the attacker generate a valid PAC for their chosen malicious address.

With pointer authentication enabled, an attacker is never able to overwrite pointers on the stack (including the rip) without generating the corresponding secret for the attackerâ€™s malicious address. Without knowing the key, the attacker is forced to guess the correct secret value for their address. For a 20-bit secret, the attacker has a 1 inÂ 220Â chance of success.

Another way to subvert pointer authentication is to find a separate vulnerability in the program that allows the attacker to trick the program into creating a validated pointer. The attacker could also try to discover the secret key stored in the CPU, or find a way to subvert the functionÂ fÂ used to generate the secret values.


### Address Space Layout Randomization (ASLR)
> â†— [ASLR (Address Space Layout Randomization)](ASLR%20(Address%20Space%20Layout%20Randomization).md)

#### Subverting ASLR
The two main ways to subvert ASLR are similar to the main ways to subvert the stack canary: guess the address, or leak the address.

**Guess the address**: Because of the constraints on address randomization, a 32-bit system will sometimes only have around 16 bits of entropy for address randomization. In other words, the attacker can guess the correct address with a 1 inÂ 216Â probability, or the attacker can try the exploitÂ 216Â times and expect to succeed at least once. This is less of a problem on 64-bit systems, which have more entropy available for address randomization.

Like guessing the stack canary, the feasibility of guessing addresses in ASLR depends on the attack setting. For example, if each try takes 1 second, then the attacker can makeÂ 216Â attempts in less than a day. However, if each try after a crash takes exponentially longer,Â 216Â attempts may become infeasible.

**Leak the address**: Sometimes the program has a vulnerability that allows the attacker to read parts of memory. For example, a format string vulnerability might let the attacker print out values from the stack. The stack often stores absolute addresses, such as pointers and saved registers (`sfp` and `rip`). If the attacker can leak an absolute address, they may be able to determine the absolute address of other parts of memory relative to the absolute address they leaked.

Note that ASLR randomizes absolute addresses by changing the start of sections of memory, but it does not randomize theÂ _relative_Â addresses of variables. For example, even if ASLR is enabled, the rip will still be 4 bytes above the `sfp` in a function stack frame. This means that an attacker who leaks the absolute address of the `sfp` could deduce the address of the rip (and possibly other values on the stack).


### Control Flow Integrity (CFI)
â†— [CFI (Control-Flow Integrity)](CFI%20(Control-Flow%20Integrity).md)



## Ref
[ç¼“å†²åŒºæº¢å‡ºä¸æ”»é˜²åšå¼ˆ]: https://cloud.tencent.com/developer/article/2201574

å¾®è½¯çš„å†…å­˜ä¿æŠ¤æœºåˆ¶å¤§è‡´åˆ†ä¸ºä»¥ä¸‹å‡ ç§ï¼š
1. å †æ ˆç¼“å†²åŒºæº¢å‡ºæ£€æµ‹ä¿æŠ¤ GS (ç¼–è¯‘å™¨)
2. å®‰å…¨ç»“æ„åŒ–å¼‚å¸¸å¤„ç†ä¿æŠ¤ Safe SEH
3. å †æ ˆ SEH è¦†ç›–ä¿æŠ¤ SEHOP
4. åœ°å€ç©ºé—´å¸ƒå±€éšæœºåŒ–ä¿æŠ¤ ASLR
5. å †æ ˆæ•°æ®æ‰§è¡Œä¿æŠ¤ DEP

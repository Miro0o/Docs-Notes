# Theory of Computation

[TOC]



## Res
### Related Topics
â†— [Set Theory & Axiomatic Set Theory](../ğŸ›’%20Set%20Theory%20&%20Axiomatic%20Set%20Theory/Set%20Theory%20&%20Axiomatic%20Set%20Theory.md)
â†— [Graph Theory](../../Graph%20Theory/Graph%20Theory.md)
â†— [Proof Theory](../Proof%20Theory/Proof%20Theory.md)

â†— [Mathematical Modeling & Real World Problem Solving](../../Mathematical%20Modeling%20&%20Real%20World%20Problem%20Solving.md)

â†— [Natural Language Processing (NLP) & Computational Linguistics](../../../ğŸ§ %20Computing%20Methodologies/ğŸ‘½%20Artificial%20Intelligence/âšœï¸%20Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics.md)


### Learning Resources
ğŸ¬ã€ã€åŒ—äº¬å¤§å­¦ã€‘ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆå…¨70è®²ï¼‰ã€‘ https://www.bilibili.com/video/BV1m4411p7nS/?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d
https://mannuan.github.io/è®¡ç®—ç†è®ºè¯¾ä»¶/
ä¸»è®²è€å¸ˆï¼šåˆ˜ç”°

ğŸ¬ã€ã€MIT18.404ã€‘è®¡ç®—ç†è®ºåŸºç¡€(å®Œç»“)â€”ç†è®ºç ”ç©¶æˆ–ç®—æ³•åº”ç”¨çš„åŸºç¡€è¯¾ã€‘ https://www.bilibili.com/video/BV1qL411s7mr/?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d - Michael Sipser

ğŸ“– Introduction to the Theory of Computation, 3rd edition, by Michael Sipser
- [Sipers-computation-3rd-solutions](https://github.com/gaurangsaini/sipser-computation-3rd-solutions)
- This book focuses on three traditionally central areas of the theory of computation: automata, computability, and complexity. They are linked by the question: 
	- What are the fundamental capabilities and limitations of computers?

ğŸ“‚ https://hackmd.io/2AqODdrtTOuj6fb5uMDZYw?view
The goal is to build a collection of videos for an undergraduate Theory of Computation course. We hope that this collection of videos would be a useful community resource for flipped classes. The intent is that these videos can be used in a flipped class format. The flipped format has been quite successful for other topics and seems well suited to remote teaching that many of us are doing. The instructor can choose to use these videos in whatever fashion he/she thinks best. These videos will ideally be supplemented by classroom discussion, practice exercises and assignments as part of the course.

ğŸ“– [Computational Complexity: A Modern Approach](http://www.cs.princeton.edu/theory/complexity/)Â by Arora and Barak.
ğŸ“– Introduction to automata theory,Â languages, and computationÂ / by John E. Hopcroft,. Rajeev Motwani, Jeffrey D. Ullman. --Â _3rd ed_.

ğŸ“– [Computational Complexity](http://rads.stackoverflow.com/amzn/click/0201530821)Â by Papadimitriou
ğŸ“– [Computability and Logic](https://www.cambridge.org/core/books/computability-and-logic/440B4178B7CBF1C241694233716AB271)Â by George S. Boolos and John P. Burgess.
ğŸ“– [Oded Goldreich's textbook](http://rads.stackoverflow.com/amzn/click/052188473X)

ğŸ‘¨â€ğŸ’» https://www.mropengate.com/2015/06/formal-language.html
è¨ˆç®—ç†è«–æ˜¯è¨ˆç®—æ©Ÿç§‘å­¸çš„éˆé­‚ - åœ‹ç«‹é™½æ˜äº¤é€šå¤§å­¸
ä¸€ã€æ­£å‰‡èªè¨€ Regular Languages  
- [Ch1 æ±ºå®šæ€§æœ‰é™è‡ªå‹•æ©Ÿ Deterministic Finite automata, DFA](http://mropengate.blogspot.tw/2015/03/formal-language-ch11-finite-automata.html)
- [Ch2 éæ±ºå®šæ€§æœ‰é™è‡ªå‹•æ©Ÿ Nondeterminism Finite automata, NFA](http://mropengate.blogspot.tw/2015/04/formal-language-ch2-nondeterminism.html)
- [Ch3Â æ­£å‰‡è¡¨é”å¼ Regular Expression, RE](http://mropengate.blogspot.tw/2015/04/formal-language-ch3-regular-expression.html)
- [Ch3.5 å¸¸ç”¨çš„æ­£å‰‡è¡¨ç¤ºå¼ Regular Expression in Application](http://mropengate.blogspot.tw/2015/02/regular-expression.html)
- [Ch4 æ³µå¼•ç† Pumping Lemma](http://mropengate.blogspot.tw/2015/04/formal-language-ch4-pumping-lemma.html)
- [Ch5Â é‚å¸Œçˆ¾ï¼å°¼ç¾…å¾·å®šç† Myhill-Nerode Theorem](http://mropengate.blogspot.tw/2015/04/formal-language-ch5-myhill-nerode.html)
äºŒã€ä¸Šä¸‹æ–‡ç„¡é—œèªè¨€ Context-Free Languages  
- [Ch6 ä¸Šä¸‹æ–‡ç„¡é—œèªè¨€ Context-free language, CFLs](http://mropengate.blogspot.tw/2015/04/formal-language-ch6-context-free.html)
- [Ch7 ä¸‹æ¨è‡ªå‹•æ©Ÿ Pushdown automaton, PDAs](http://mropengate.blogspot.tw/2015/04/formal-language-ch7-pushdown-automaton.html)
- [Ch8 ä¸Šä¸‹æ–‡ç„¡é—œèªè¨€æ³µå¼•ç† Pumping lemma for context free languages](http://mropengate.blogspot.tw/2015/04/formal-language-ch7-pumping-lemma-for.html)
ä¸‰ã€é‚±å¥‡ï¼åœ–éˆè«–é¡Œ Churchâ€“Turing Thesis  
- [Ch9Â åœ–éˆæ©Ÿ Turing Machines](http://mropengate.blogspot.tw/2015/05/formal-language-ch9-turing-machines.html)
- [Ch10 è®Šç¨®åœ–éˆæ©Ÿ Variants of Turing Machines](http://mropengate.blogspot.tw/2015/05/formal-language-ch10-variants-of-turing.html)
å››ã€æ±ºå®šæ€§å•é¡Œ Decidability  
- [Ch11 æ±ºå®šæ€§å•é¡Œ Decidability](http://mropengate.blogspot.tw/2015/05/formal-language-ch11-decidability.html)
- [Ch12 ä¸å¯æ±ºå®šå•é¡Œèˆ‡åœ–éˆå¯è­˜åˆ¥èªè¨€ Undecidable Problem and Turing-recognizable language](http://mropengate.blogspot.tw/2015/05/formal-language-undecidable-problem.html)
- [Ch12.5 æ±ºå®šèˆ‡ä¸å¯æ±ºå®šå•é¡Œç›¸é—œç¿’é¡Œ](http://mropengate.blogspot.tw/2015/05/formal-language-ch125.html)
äº”ã€æ­¸ç´„ Reducibility  
- [Ch13 å¯æ­¸ç´„æ€§ Reducibility](http://mropengate.blogspot.tw/2015/05/formal-language-ch13-reducibility.html)
- [Ch14 å¤šä¸€æ­¸ç´„ Mapping Reducibility](http://mropengate.blogspot.tw/2015/05/formal-language-ch14-mapping.html)
- [Ch14.5 æ­¸ç´„ç›¸é—œç¿’é¡Œ Exercises for Reducibility](http://mropengate.blogspot.tw/2015/05/formal-language-ch145-exercises-mapping.html)
å…­ã€æ™‚é–“è¤‡é›œåº¦ Time Complexity  
- [Ch15 è¤‡é›œåº¦På’ŒNP Time Complexity, P and NP](http://mropengate.blogspot.tw/2015/06/formal-language-ch15-pnp-time.html)
- [Ch16 NPå®Œå…¨ NP-Complete, NPC](http://mropengate.blogspot.tw/2015/06/formal-language-ch16-np-np-complete-npc.html)
- [Ch16.5 Cook-Levinç†è«–èˆ‡å¡æ™®çš„äºŒåä¸€å€‹NP-å®Œå…¨å•é¡Œ](http://mropengate.blogspot.tw/2015/06/algorithm-cook-levinnp.html)

https://zemdalk.github.io/archive.html?tag=ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€
- 06æœˆ02æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ13ï¼‰â€”â€”NLå®Œå…¨ã€NL=coNL](https://zemdalk.github.io/2022/06/02/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-13.html)
- 05æœˆ31æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ12ï¼‰â€”â€”PSPACEå®Œå…¨](https://zemdalk.github.io/2022/05/31/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-12.html)
- 05æœˆ30æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ11ï¼‰â€”â€”ç©ºé—´å¤æ‚æ€§ç±»](https://zemdalk.github.io/2022/05/30/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-11.html)
- 05æœˆ19æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ10ï¼‰â€”â€”æ›´å¤šNPå®Œå…¨é—®é¢˜](https://zemdalk.github.io/2022/05/19/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-10.html)
- 05æœˆ13æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ9ï¼‰â€”â€”NPå®Œå…¨é—®é¢˜](https://zemdalk.github.io/2022/05/13/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-9.html)
- 05æœˆ12æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ8ï¼‰â€”â€”æ—¶é—´å¤æ‚æ€§](https://zemdalk.github.io/2022/05/12/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-8.html)
- 04æœˆ25æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ7ï¼‰â€”â€”å›¾çµå½’çº¦](https://zemdalk.github.io/2022/04/25/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-7.html)
- 04æœˆ15æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ6ï¼‰â€”â€”é€’å½’å®šç†](https://zemdalk.github.io/2022/04/15/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-6.html)
- 04æœˆ07æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ5ï¼‰â€”â€”å¯å½’çº¦æ€§](https://zemdalk.github.io/2022/04/07/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-5.html)
- 03æœˆ31æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ4ï¼‰â€”â€”å¯è®¡ç®—æ€§](https://zemdalk.github.io/2022/03/31/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-4.html)
- 03æœˆ28æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ3ï¼‰â€”â€”å›¾çµæœº](https://zemdalk.github.io/2022/03/28/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80-3.html)
- 03æœˆ14æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ2ï¼‰â€”â€”ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•](https://zemdalk.github.io/2022/03/14/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80-2.html)
- 02æœˆ22æ—¥[ç†è®ºè®¡ç®—æœºç§‘å­¦åŸºç¡€ï¼ˆ1ï¼‰â€”â€”ç»ªè®ºã€æ­£åˆ™è¯­è¨€](https://zemdalk.github.io/2022/02/22/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80-1.html)



## Intro
![](../../../../../Assets/Pics/Screenshot%202023-05-08%20at%204.26.42%20PM.png)
<small>What can computers do?</small>

> ğŸ”— https://en.wikipedia.org/wiki/Theory_of_computation

InÂ [theoretical computer science](https://en.wikipedia.org/wiki/Theoretical_computer_science "Theoretical computer science")Â andÂ [mathematics](https://en.wikipedia.org/wiki/Mathematics "Mathematics"), theÂ **theory of computation**Â is the branch that deals with what problems can be solved on aÂ model of computation, using anÂ algorithm, howÂ efficientlyÂ they can be solved or to what degree (e.g.,Â [approximate solutions](https://en.wikipedia.org/wiki/Approximation_algorithms "Approximation algorithms")versus precise ones). The field is divided into three major branches:
1. [automata theory](https://en.wikipedia.org/wiki/Automata_theory "Automata theory")Â andÂ [formal languages](https://en.wikipedia.org/wiki/Formal_language "Formal language")
	1. æœ‰å“ªäº›è®¡ç®—è£…ç½®ï¼Ÿèƒ½åŠ›å¦‚ä½•
	2. æœ‰ç©·ï¼ˆæ— ç©·ï¼‰è‡ªåŠ¨æœº /ä¸‹æ¨è‡ªåŠ¨æœº /å›¾çµæœº
	3. æ­£åˆ™è¯­è¨€ /ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ /å¯è®¡ç®—è¯­è¨€ /åŠå¯è®¡ç®—è¯­è¨€
2. [computability theory](https://en.wikipedia.org/wiki/Computability_theory "Computability theory")
	1. ä»€ä¹ˆæ˜¯è®¡ç®—ï¼Ÿå“ªäº›é—®é¢˜å¯ä»¥è®¡ç®—/ä¸å¯ä»¥è®¡ç®—ï¼Ÿ
	2. ä¸˜å¥‡-å›¾çµè®ºé¢˜ /é€šç”¨æœº /åœæœºé—®é¢˜ /è§„çº¦ /é€’å½’å®šç†
3. [computational complexity theory](https://en.wikipedia.org/wiki/Computational_complexity_theory "Computational complexity theory"), which are linked by the question:Â _"What are the fundamental capabilities and limitations of computers?"._
	1. ä»€ä¹ˆæ˜¯æœ‰æ•ˆè®¡ç®—ï¼Ÿå“ªäº›é—®é¢˜å¯ä»¥/ä¸å¯ä»¥æœ‰æ•ˆè®¡ç®—ï¼Ÿ
	2. æ—¶é—´å¤æ‚æ€§ /ç©ºé—´å¤æ‚æ€§ /å¤šé¡¹å¼æ—¶é—´å½’çº¦ /å®Œå…¨é—®é¢˜

---
> ğŸ”— https://www.mropengate.com/2015/06/formal-language.html

é€éè¨ˆç®—æ¨¡å‹ï¼Œæˆ‘å€‘å¯ä»¥å°è¨ˆç®—å®šä¸‹æ˜ç¢ºçš„æ•¸å­¸å®šç¾©ã€‚è€Œä¸€æ—¦æœ‰äº†æ˜ç¢ºçš„å®šç¾©ï¼Œä¾¿å¯ä»¥ç ”ç©¶ä»€éº¼æ˜¯å¯è¨ˆç®—çš„ã€ä»€éº¼æ˜¯ä¸å¯è¨ˆç®—çš„ï¼Œè€Œå°æ–¼å¯è¨ˆç®—çš„å•é¡Œï¼Œå¿…é ˆèŠ±è²»å¤šå°‘æ™‚é–“å’Œç©ºé–“æ‰å¯èƒ½è¨ˆç®—ã€‚  
  
Churchâ€“Turing thesis æŒ‡å‡ºï¼Œæ‰€æœ‰æ¼”ç®—æ³•å¯è§£çš„å•é¡Œï¼Œéƒ½å¯é€é Turing machines æ±‚è§£ï¼Œä¹Ÿå› æ­¤ï¼Œè—‰ç”±ç ”ç©¶ Turing machines æˆ‘å€‘å¾—ä»¥æ¢è¨é›»è…¦çš„æ¥µé™ï¼Œä»¥åŠå°å„ç¨®å•é¡Œçš„é›£åº¦è¨‚å‡ºæ˜ç¢ºçš„ç•Œç·šã€‚  
  
é€™æ˜¯ä¸€é–€éå¸¸ç†è«–èˆ‡æ•¸å­¸çš„èª²ï¼Œéœ€è¦éå¸¸æ¸…æ™°çš„é‚è¼¯æ€è€ƒã€‚è€å¸«æ›¾èªªï¼Œè³‡è¨Šç•Œæ—¥æ–°æœˆç•°ï¼Œè¨±å¤šèª²ç¨‹å¯èƒ½å¹¾å¹´å¾Œå°±ä¸è¦‹äº†ï¼Œæˆ–è€…æ•™çš„æ±è¥¿å¤§å¹…æ”¹è®Šã€‚ä½†ä½ å¹¾ä¹å¯ä»¥ç¢ºå®šï¼Œæ­£è¦èªè¨€é€™é–€èª²é‚„æ˜¯æœƒä¸€ç›´å­˜åœ¨ã€‚å¾å“²å­¸çš„è§’åº¦ä¾†èªªï¼Œè¨ˆç®—ç†è«–åœ¨é›»è…¦ç§‘å­¸è£¡ä½”äº†ååˆ†æ ¸å¿ƒçš„åœ°ä½ã€‚  
  
æ­£è¦èªè¨€èª²ç¨‹æ‰€å­¸çš„æ±è¥¿å…¶å¯¦ä¹Ÿæœ‰å¾ˆå¤šå»¶ä¼¸çš„æ‡‰ç”¨ï¼Œä»¥è‡³æ–¼å¾ˆå¤šè®€è€…å¾ˆå¯èƒ½æ—©å·²æ¥è§¸éæŸäº›éƒ¨ä»½ï¼Œä½†ç›´åˆ°é€™é–€èª²ï¼Œæ‰çœŸæ­£ä»¥åš´è¬¹çš„æ–¹å¼å­¸ç¿’èƒŒå¾Œçš„ä¾†æ­·ã€‚åƒæ˜¯å¦‚æœæœ‰æ¥è§¸åƒ Python ç­‰èªè¨€æˆ–è€…ç”¨é Vim ç­‰ç·¨è¼¯å™¨çš„æœå°‹åŠŸèƒ½çš„è®€è€…ï¼Œå¾ˆæœ‰å¯èƒ½æœ‰æ¥è§¸éæ­£è¦è¡¨ç¤ºå¼ã€‚è€Œ CFG å’Œç¨‹å¼èªè¨€çš„è¨­è¨ˆä»¥åŠç·¨è­¯å™¨ç­‰èª²ç¨‹æœ‰å¯†åˆ‡ç›¸é—œï¼Œä½ æˆ–è¨±æœƒæ›¾åœ¨ç¨‹å¼èªè¨€çš„æ–‡ä»¶ä¸Šçœ‹éä»–ã€‚å¦‚æœåœ¨æ¼”ç®—æ³•ç­‰èª²ç¨‹è½é NPã€P ç­‰åè©ï¼Œåœ¨é€™å ‚èª²è£¡ï¼Œä½ å¯ä»¥å­¸åˆ°é€™äº›åè©åˆ°åº•æœ‰ä»€éº¼å«æ„ã€‚è€Œå°ä»€éº¼æ˜¯æ¼”ç®—æ³•ï¼Œæ™‚é–“è¤‡é›œåº¦ã€å•é¡Œçš„å¯è¨ˆç®—æ€§ç­‰ç­‰ï¼Œéƒ½æœƒåœ¨é€™å ‚èª²å¾—åˆ°æ›´æ·±çš„ç†è§£ã€‚

---

> ğŸ“–  Introduction to the Theory of Computation, 3rd edition, by Michael Sipser, CH0, Introduction

This book focuses on three traditionally central areas of the theory of computation: automata, computability, and complexity. They are linked by the question:

> **What are the fundamental capabilities and limitations of computers?**

This question goes back to the 1930s when mathematical logicians first began to explore the meaning of computation. Technological advances since that time have greatly increased our ability to compute and have brought this question out of the realm of theory into the world of practical concern.

In each of the three areasâ€”automata, computability, and complexity -- this question is interpreted differently, and the answers vary according to the interpretation. Following this introductory chapter, we explore each area in a separate part of this book. Here, we introduce these parts in reverse order because by starting from the end you can better understand the reason for the beginning.

**COMPLEXITY THEORY**
Computer problems come in different varieties; some are easy, and some are hard. For example, the sorting problem is an easy one. Say that you need to arrange a list of numbers in ascending order. Even a small computer can sort a million numbers rather quickly. Compare that to a scheduling problem. Say that you must find a schedule of classes for the entire university to satisfy some reasonable constraints, such as that no two classes take place in the same room at the same time. The scheduling problem seems to be much harder than the sorting problem. If you have just a thousand classes, finding the best schedule may require centuries, even with a supercomputer.

> **What makes some problems computationally hard and others easy?**

This is the central question of complexity theory. Remarkably, we donâ€™t know the answer to it, though it has been intensively researched for over 40 years. Later, we explore this fascinating question and some of its ramifications. 

In one important achievement of complexity theory thus far, researchers have discovered an elegant scheme for classifying problems according to their computational difficulty. It is analogous to the periodic table for classifying elements according to their chemical properties. Using this scheme, we can demonstrate a method for giving evidence that certain problems are computationally hard, even if we are unable to prove that they are.

You have several options when you confront a problem that appears to be computationally hard. First, by understanding which aspect of the problem is at the root of the difficulty, you may be able to alter it so that the problem is more easily solvable. Second, you may be able to settle for less than a perfect solution to the problem. In certain cases, finding solutions that only approximate the perfect one is relatively easy. Third, some problems are hard only in the worst case situation, but easy most of the time. Depending on the application, you may be satisfied with a procedure that occasionally is slow but usually runs quickly. Finally, you may consider alternative types of computation, such as randomized computation, that can speed up certain tasks.

One applied area that has been affected directly by complexity theory is the ancient field of cryptography. In most fields, an easy computational problem is preferable to a hard one because easy ones are cheaper to solve. Cryptography is unusual because it specifically requires computational problems that are hard, rather than easy. Secret codes should be hard to break without the secret key or password. Complexity theory has pointed cryptographers in the direction of computationally hard problems around which they have designed revolutionary new codes.

**COMPUTABILITY THEORY**
During the first half of the twentieth century, mathematicians such as Kurt Godel, Alan Turing, and Alonzo Church discovered that certain basic problems cannot be solved by computers. One example of this phenomenon is the problem of determining whether a mathematical statement is true or false. This task is the bread and butter of mathematicians. It seems like a natural for solution by computer because it lies strictly within the realm of mathematics. But no computer algorithm can perform this task.

Among the consequences of this profound result was the development of ideas concerning theoretical models of computers that eventually would help lead to the construction of actual computers.

The theories of computability and complexity are closely related. In complexity theory, the objective is to classify problems as easy ones and hard ones; whereas in computability theory, the classification of problems is by those that are solvable and those that are not. Computability theory introduces several of the concepts used in complexity theory.

**AUTOMATA THEORY**
Automata theory deals with the definitions and properties of mathematical models of computation. These models play a role in several applied areas of computer science. One model, called the finite automaton, is used in text processing, compilers, and hardware design. Another model, called the context-free grammar, is used in programming languages and artificial intelligence.

Automata theory is an excellent place to begin the study of the theory of computation. The theories of computability and complexity require a precise definition of a computer. Automata theory allows practice with formal definitions of computation as it introduces concepts relevant to other non-theoretical areas of computer science.



## Models of Computation
> â†— [Mathematical Modeling & Real World Problem Solving](../../Mathematical%20Modeling%20&%20Real%20World%20Problem%20Solving.md)
> â†— [(Formal) Model Checking /1ï¸âƒ£ System Modeling](../../../CyberSecurity/ğŸ°%20Cybersecurity%20Basics%20&%20InfoSec/ğŸ¦%20Software%20Security/ğŸª†%20Software%20(Program)%20Analysis%20&%20Binary%20Engineering/ğŸ“Œ%20Software%20(Program)%20Analysis%20Basics/ğŸ™‡â€â™‚ï¸%20Formal%20Methods%20&%20Formal%20Verification%20(FV)/(Formal)%20Model%20Checking/(Formal)%20Model%20Checking.md#1ï¸âƒ£%20System%20Modeling)
> â†— [The Essence of Computing - Programs & The Semantics of Programs](../../../ğŸ—º%20CS%20Overview/The%20Essence%20of%20Computing%20-%20Programs%20&%20The%20Semantics%20of%20Programs.md)
> â†— [Formal Semantics and Programming Language](../../../ğŸ”‘%20CS%20Core/ğŸ‘©â€ğŸ’»%20Computer%20Languages%20&%20Programming%20Methodology/ğŸ¢%20Programming%20Language%20Theory%20(PLT)/Formal%20Semantics%20and%20Programming%20Language/Formal%20Semantics%20and%20Programming%20Language.md)
> 
> â†— [Proof Theory](../Proof%20Theory/Proof%20Theory.md)
> â†— [Curryâ€“Howard(â€“Lambek) Correspondence](../Proof%20Theory/Curryâ€“Howard(â€“Lambek)%20Correspondence.md)

![Drawing 2025-09-09 22.37.45.excalidraw | 800](../../../../../Assets/Illustrations/Computer%20Language/Language_and_Programming_Language_Processing.md)
<small>The process of compilation</small>

> ğŸ”— https://en.wikipedia.org/wiki/Model_of_computation

In computer science, and more specifically in computability theory and computational complexity theory, a model of computation is a model which describes how an output of a mathematical function is computed given an input. A model describes how units of computations, memories, and communications are organized. The computational complexity of an algorithm can be measured given a model of computation. Using a model allows studying the performance of algorithms independently of the variations that are specific to particular implementations and specific technology.


### (Symbolic) Transition System â­
> â†— [The Essence of Computing - Programs & The Semantics of Programs](../../../ğŸ—º%20CS%20Overview/The%20Essence%20of%20Computing%20-%20Programs%20&%20The%20Semantics%20of%20Programs.md)
> - programs are transition systems
> - hardware circuits are transition systems
> - communication processes are transition systems
> - etc.

> ğŸ”— https://en.wikipedia.org/wiki/Transition_system

InÂ [theoretical computer science](https://en.wikipedia.org/wiki/Theoretical_computer_science "Theoretical computer science"), aÂ **transition system**Â is a concept used in the study ofÂ [computation](https://en.wikipedia.org/wiki/Computation "Computation"). It is used to describe the potential behavior ofÂ [discrete systems](https://en.wikipedia.org/wiki/Discrete_system "Discrete system"). It consists ofÂ [states](https://en.wikipedia.org/wiki/State_\(computer_science\) "State (computer science)")Â and transitions between states, which may be labeled with labels chosen from a set; the same label may appear on more than one transition. If the label set is aÂ [singleton](https://en.wikipedia.org/wiki/Singleton_\(mathematics\) "Singleton (mathematics)"), the system is essentially unlabeled, and a simpler definition that omits the labels is possible.

Transition systems coincide mathematically withÂ [abstract rewriting systems](https://en.wikipedia.org/wiki/Abstract_rewriting_system "Abstract rewriting system")Â (as explained further in this article) andÂ [directed graphs](https://en.wikipedia.org/wiki/Directed_graph "Directed graph"). They differ fromÂ [finite-state automata](https://en.wikipedia.org/wiki/Finite-state_automata "Finite-state automata")Â in several ways:
- The set of states is not necessarily finite, or even countable.
- The set of transitions is not necessarily finite, or even countable.
- No "start" state or "final" states are given.

Transition systems can be represented as **directed graphs**.

---
**Formal Definition of Transition System**

Formally, aÂ **transition system**Â is a pairÂ $(S,T)$Â whereÂ $S$Â is a set of states andÂ $T$, theÂ _transition relation_, is a subset ofÂ $S\times S$. We say that there is a transition from stateÂ $p$Â to stateÂ $q$Â ifÂ $(p,q)\in T$, and denote itÂ $p\to q$.

AÂ **labelled transition system**Â is a tupleÂ $(S,\Lambda,T)$Â whereÂ $S$Â is a set of states,Â $\Lambda$Â is a set of labels, andÂ $T$, theÂ _labelled transition relation_, is a subset ofÂ $S\times\Lambda\times S$. We say that there is a transition from stateÂ $p$Â to stateÂ $q$Â with labelÂ $\alpha \iffÂ (p,\alpha ,q)\in T$Â and denote it $p\xrightarrow {\alpha } q$.

Labels can represent different things depending on the language of interest. Typical uses of labels include representing input expected, conditions that must be true to trigger the transition, or actions performed during the transition. Labelled transitions systems were originally introduced asÂ _named_Â transition systems.


**Special cases**
- If, for any givenÂ $p$Â andÂ $\alpha$, there exists only a single tupleÂ $(p,Î±,q)$Â inÂ $T$, then one says thatÂ Î±![{\displaystyle \alpha }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3)Â is ==deterministicÂ (forÂ $p$)==.
- If, for any givenÂ $p$Â andÂ $\alpha$, there exists at least one tupleÂ $(p,\alpha,q)$Â inÂ $T$, then one says thatÂ $\alpha$Â isÂ ==executable (forÂ $p$)==.


**Coalgebra Formulation**
The formal definition can be rephrased as follows. Labelled state transition systems onÂ $S$Â with labels fromÂ $\Lambda$Â correspondÂ [one-to-one](https://en.wikipedia.org/wiki/Bijection "Bijection")Â with functionsÂ $S\to P(\Lambda\times S)$, whereÂ $P$Â is the (covariant)Â [powerset functor](https://en.wikipedia.org/wiki/Power_set "Power set"). Under this bijectionÂ $(S,\Lambda,T)$Â is sent to $\xi _{T}:S\to {\mathcal {P}}(\Lambda \times S)$, defined by $$p\mapsto \{\,(\alpha ,q)\in \Lambda \times S\mid p\xrightarrow {\alpha } q\,\}$$
In other words, a labelled state transition system is aÂ [coalgebra](https://en.wikipedia.org/wiki/F-coalgebra "F-coalgebra")Â for the functorÂ $P(\Lambda \times {-})$

InÂ [model checking](https://en.wikipedia.org/wiki/Model_checking "Model checking"), a transition system is sometimes defined to include an additional labeling function for the states as well, resulting in a notion that encompasses that ofÂ [Kripke structure](https://en.wikipedia.org/wiki/Kripke_structure "Kripke structure").


**Forward and backwards reachability**
We sometimes need to talk about how states can reach each other.
The set of direct successors of a state s is defined as
ğ‘ƒğ‘œğ‘ ğ‘¡(ğ‘ ) = {ğ‘  âˆ£ âˆƒğ›¼. ğ‘  ğ›¼â†’ğ‘ â€²}
Similarly, we can define the direct predecessors of a state s as
ğ‘ƒğ‘Ÿğ‘’(ğ‘ ) = {ğ‘  âˆ£ âˆƒğ›¼. ğ‘ â€² ğ›¼â†’ğ‘ }
The above definitions can be lifted to sets of states A.
ğ‘ƒğ‘œğ‘ ğ‘¡(ğ´) =
. . .
ğ‘ƒğ‘Ÿğ‘’(ğ´) =
. . .
Successors/predecessors in any number of transitions can be defined likewise.
On a related note, one is typically interested in the part of a transition system that is
reachable from the initial state(s).


**Non-deterministic & Deterministic Transition System**
A transition system is action-deterministic iff
(1) There is no more than 1 initial state
|ğ¼| â‰¤ 1
(2) For every state s and every action a, there is only one outgoing transition from s
labelled with a.
|{ğ‘ â€² âˆ£ ğ‘  ğ‘â†’ğ‘ â€²}| â‰¤ 1


**Terminal States**
A state is a terminal state if it has no outgoing transition.
We can write this formally in several ways: a state s is terminal iff
Â¬âˆƒğ‘ â€²
. ğ‘  â†’ ğ‘ â€²
ğ‘ƒğ‘œğ‘ ğ‘¡(ğ‘ ) = âˆ…
Terminal states usually represent final states (the system finished doing its job)
â€¦or deadlock states (the system is stuck).

**Transition systems with no terminals**
From now on we consider w.l.o.g. transition systems with no terminal states.
If you have a terminal state, just add a self-loop.
If you are interested in marking the state as â€œterminalâ€ and distinguish it from proper self-loops, just add as special label to it.


####  Kripke Structure (of Transition System)
> ğŸ”— https://en.wikipedia.org/wiki/Kripke_structure_(model_checking)

AÂ **Kripke structure**Â is a variation of theÂ [transition system](https://en.wikipedia.org/wiki/Transition_system "Transition system"), originally proposed byÂ [Saul Kripke](https://en.wikipedia.org/wiki/Saul_Kripke "Saul Kripke"),Â used inÂ [model checking](https://en.wikipedia.org/wiki/Model_checking "Model checking")Â to represent the behavior of a system. It consists of aÂ [graph](https://en.wikipedia.org/wiki/Graph_\(discrete_mathematics\) "Graph (discrete mathematics)")Â whose nodes represent the reachable states of the system and whose edges represent state transitions, together with a labelling function which maps each node to a set of properties that hold in the corresponding state.Â [Temporal logics](https://en.wikipedia.org/wiki/Temporal_logic "Temporal logic")Â are traditionally interpreted in terms of Kripke structures.

---
**Formal Definition of Kripke Structure**

A transition system (of Kripke Structure) $TS$ is a tuple $(S,Act,\to,I,AP,L)$ where
- $S$ is a set of states,
- $Act$ is a set of actions,
- $\to \subseteq S \times Act \times S$ is a transition relation,
	-  or use $\delta$ to express $\to$
- $I \subseteq S$ is a set of initial states,
	- $\sigma\in I$
	- or, when using $\tau$ or $\pi$ to symbol a trace on $TS$, $\tau_0 = \sigma \in I$ or $\pi_0=\sigma\in I$
- $AP$ is a set of atomic propositions, 
- $L$: $Sâ†’AP^2$ is a labeling function.

$TS$ is called **finite** if $S$, $Act$, and $AP$ are **finite**.

It is important to realize that in case a state has more than one outgoing transition, the
â€œnextâ€ transition is chosen in a purely **nondeterministic** fashion. That is, the outcome of
this selection process is not known a priori, and, hence, no statement can be made about the likelihood with which a certain transition is selected. Similarly, when the set of initial states consists of more than one state, the start state is selected nondeterministically.

For convenience, we write $s \xrightarrow[]{\alpha}s'$ instead of $(s,Î±,s') \in \to$.

The labeling function $L$ relates a set $L(s) \in AP^2$ of atomic propositions to any state $s$. $L(s)$ intuitively stands for exactly those atomic propositions $a \in AP$ which are satisfied by state $s$. Given that $Î¦$ is a propositional logic formula, then $s$ satisfies the formula $Î¦$ if the evaluation induced by $L(s)$ makes the formula Î¦ true; that is: $s \models \Phi \iff L(s) \models \Phi$.

![](../../../../../../../../Assets/Pics/Screenshot%202025-09-23%20at%2018.33.15.png)
<small><a>https://www.cs.cmu.edu/~emc/15414-f12/lecture/temporal_logics.pdf#page=1.00</a></small>
![](../../../../../../../../Assets/Pics/Screenshot%202025-09-23%20at%2018.34.43.png)
<small><a>https://www.cs.cmu.edu/~emc/15414-f12/lecture/temporal_logics.pdf#page=1.00</a></small>
#### Semantics of Transition System
> â†— [Graph Basics](../../Graph%20Theory/ğŸ“Œ%20Graph%20Theory%20Basics/Graph%20Basics.md)
##### Execution & Trace
**Execution**
An execution fragment is a sequence of transitions.
$s_0\overset{click}{\to}s_1\overset{click}{\to}s_2...$

An execution is finite/infinite if the sequence is finite/infinite.
$s_0\overset{click}{\to}s_1 \text{ or }(s_2\overset{click}{\to}s_2)^w$

An execution is initial if the first state of the sequence is in I.

An execution is maximal if it cannot be extended: either it is finite and the last state is a terminal state, or it is infinite.

NOTE: by our assumption of â€œno terminal stateâ€, only the second case applies.
NOTE: often, we drop the arrows.


**Trace**
Executions may contain too much information, i.e. actual states.
Often, one is interested in the **atomic properties** of states.
Replacing every state in an execution by its atomic properties yields a trace.

We may even drop the transitions and their actions.
##### Computational Tree
Executions and traces can be seen as the system running with a fixed scheduler.
They are not appropriate if we want to see how the system makes choices.
Computation trees can save the day!

**A computation tree is a tree whose nodes are states of a TS (or their atomic propositions).**

The successor of each state in the computation tree is the immediate successor of the state as it appears in the TS.
A computation tree is the unfolding of the transition system.

![](../../../../../../../../Assets/Pics/Screenshot%202025-12-08%20at%2012.19.55.png)
#### Composing Transition System
Often, systems (and their models) are made of several components, which interact with each other.
There is a plethora of interaction mechanisms:
- Shared memory / objects / storage (consistent, weak, safe, etc.)
- Networks (synchronous/asynchronous, binary/multi-party, value-passing /rendezvous, etc.)

The transition system of the composition S1âŠ—S2 of two systems S1, S2 can be obtained in two ways.
1. Build TS(S1) and TS(S2), then compose
2. Build the composed TS directly from S1,S2

![](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.27.55.png)

We will see 2 examples of (1): pure interleaving and action-synchronisation and 1 example of (2): concurrent threads with shared memory
##### Interleaving & Synchronised Composition
Interleaving composition of concurrent threads with shared memory: 
- ![](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.28.36.png)
- ![](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.29.13.png)

Formal semantics of the composition typically specified using operational semantics (common in programming languages).

- Synchronised Composition of Transition Systems
	- ![](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.29.29.png)
###### Examples of TS Composition
- ![|400](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.30.21.png)
- ![|400](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.31.12.png)
- ![|400](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.31.31.png)
- ![|400](../../../../../../../../Assets/Pics/Screenshot%202025-12-11%20at%2018.31.44.png)
##### State Space Explosion
In general, the size of the interleaving of n transition systems of m states each is $m^n$
Synchronizations may reduce the size composition but the worstcase is still exponential in the number of components.


### Sequential Models
Sequential models include:
- [Finite-state machines](https://en.wikipedia.org/wiki/Finite-state_machine "Finite-state machine")
- Post machines ([Postâ€“Turing machines](https://en.wikipedia.org/wiki/Post%E2%80%93Turing_machine "Postâ€“Turing machine")Â andÂ [tag machines](https://en.wikipedia.org/wiki/Tag_system "Tag system")).
- [Pushdown automata](https://en.wikipedia.org/wiki/Pushdown_automata "Pushdown automata")
- [Register machines](https://en.wikipedia.org/wiki/Register_machine "Register machine")
    - [Random-access machines](https://en.wikipedia.org/wiki/Random-access_machine "Random-access machine")
- [Turing machines](https://en.wikipedia.org/wiki/Turing_machine "Turing machine")
- [Decision tree model](https://en.wikipedia.org/wiki/Decision_tree_model "Decision tree model")
- [External memory model](https://en.wikipedia.org/wiki/External_memory_model "External memory model")


### Functional Models
Functional models include:
- [Abstract rewriting systems](https://en.wikipedia.org/wiki/Abstract_rewriting_system "Abstract rewriting system")
- [Combinatory logic](https://en.wikipedia.org/wiki/Combinatory_logic "Combinatory logic")
- [General recursive functions](https://en.wikipedia.org/wiki/General_recursive_function "General recursive function")
- [Lambda calculus](https://en.wikipedia.org/wiki/Lambda_calculus "Lambda calculus")


### Concurrent Models
Concurrent models include:
- [Actor model](https://en.wikipedia.org/wiki/Actor_model "Actor model")
- [Cellular automaton](https://en.wikipedia.org/wiki/Cellular_automaton "Cellular automaton")
- [Interaction nets](https://en.wikipedia.org/wiki/Interaction_nets "Interaction nets")
- [Kahn process networks](https://en.wikipedia.org/wiki/Kahn_process_networks "Kahn process networks")
- [Logic gates](https://en.wikipedia.org/wiki/Logic_gate "Logic gate")Â andÂ [digital circuits](https://en.wikipedia.org/wiki/Circuit_\(computer_science\) "Circuit (computer science)")
- [Petri nets](https://en.wikipedia.org/wiki/Petri_nets "Petri nets")
- [Process calculus](https://en.wikipedia.org/wiki/Process_calculus "Process calculus")
- [Synchronous Data Flow](https://en.wikipedia.org/wiki/Synchronous_Data_Flow "Synchronous Data Flow")

Some of these models have bothÂ [deterministic](https://en.wikipedia.org/wiki/Deterministic_model#In_computer_science "Deterministic model")Â andÂ [nondeterministic](https://en.wikipedia.org/wiki/Nondeterministic_model_of_computation "Nondeterministic model of computation")Â variants. Nondeterministic models correspond to limits of certain sequences of finite computers, but do not correspond to any subset of finite computers;[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]Â they are used in the study ofÂ [computational complexity](https://en.wikipedia.org/wiki/Computational_complexity "Computational complexity")Â of algorithms.

Models differ in their expressive power; for example, each function that can be computed by aÂ _finite-state machine_Â can also be computed by aÂ _Turing machine_, but not vice versa.



## Ref
[è®¡ç®—æœºä¸“ä¸šå­¦è®¡ç®—ç†è®ºåŸºç¡€çš„æ„ä¹‰ï¼Ÿ - çŸ¥ä¹]: https://www.zhihu.com/question/27306122
[è®¡ç®—ç†è®ºé‡ç‚¹â€”â€”Theory of Computation]: https://blog.csdn.net/abcjennifer/article/details/8494019
[ä»€ä¹ˆæ˜¯å¯è®¡ç®—ç†è®º]: https://www.cnblogs.com/hjlweilong/p/13908517.html
[ç†è®ºè®¡ç®—æœºç§‘å­¦æµ…æ¶‰ï¼šå¯è®¡ç®—æ€§ç†è®ºï¼ˆä¸€ï¼‰]: http://niwatori.io/2018/01/13/computability-theory/

[Waht is the best text of computation theory /theory of computation | Stack Exchange]: https://cstheory.stackexchange.com/a/3527

[å¦‚ä½•é€šä¿—åœ°è§£é‡Šåœæœºé—®é¢˜ï¼ˆHalting Problemï¼‰ï¼Ÿ - å¼ çš“çš„å›ç­” - çŸ¥ä¹]: https://www.zhihu.com/question/20081359/answer/162329455
ä½œè€…ï¼šå¼ çš“  
é“¾æ¥ï¼šhttps://www.zhihu.com/question/20081359/answer/162329455  
æ¥æºï¼šçŸ¥ä¹  
è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚  

**é¢„å¤‡çŸ¥è¯†: [ç†å‘å¸ˆæ‚–è®º](https://zhida.zhihu.com/search?content_id=59575968&content_type=Answer&match_order=1&q=%E7%90%86%E5%8F%91%E5%B8%88%E6%82%96%E8%AE%BA&zhida_source=entity)**
å…‹é‡Œå…‹å²›çš„ä¸€åº§å°åŸé‡Œæœ‰ä½ç†å‘å¸ˆ, æœ‰ä¸€å¤©ä»–åšå‡ºä¸€é¡¹è§„å®š: **ä»–ç»™å¹¶ä¸”åªç»™é‚£äº›ä¸ç»™è‡ªå·±ç†å‘çš„äººç†å‘.** ç†å‘å¸ˆçš„è¿™ä¸ªè§„å®šä¼¼ä¹å¾ˆæœ‰é“ç†, æ—¢ç„¶æœ‰äººè‡ªå·±ç»™è‡ªå·±ç†å‘äº†, é‚£ä¹ˆæˆ‘å°±ä¸ç”¨"å¤šæ­¤ä¸€ä¸¾", æˆ‘å†ç»™è¿™ä¸ªäººç†å‘.

æœ€åˆ, è¿™ä¸ªè§„å®šå¹¶æ²¡ä»€ä¹ˆé—®é¢˜, åæ¥, éšç€è¿™ä¸ªç†å‘å¸ˆè‡ªå·±çš„å¤´å‘è¶Šæ¥è¶Šé•¿, ä»–å‘ç°ä»–é™·å…¥äº†ä¸€ä¸ªä¸¤éš¾çš„å¢ƒåœ°: ä»–è¯¥ä¸è¯¥ç»™è‡ªå·±ç†å‘?
- å¦‚æœä»–ä¸ºè‡ªå·±ç†å‘. é‚£ä¹ˆä»–å°±æˆä¸ºäº†ä»–è§„å®šä¸­é‚£ä¸ª"è‡ªå·±ç»™è‡ªå·±ç†å‘çš„äºº", é‚£ä¹ˆä»–å°±ä¸åº”è¯¥ä¸ºè‡ªå·±ç†å‘;
- å¦‚æœä»–ä¸ä¸ºè‡ªå·±ç†å‘, é‚£ä¹ˆä»–ä¸æ˜¯ä»–è§„å®šä¸­é‚£ä¸ª"è‡ªå·±ç»™è‡ªå·±ç†å‘çš„äºº", é‚£ä¹ˆä»–å°±åº”è¯¥ä¸ºè‡ªå·±ç†å‘.

ç»¼åˆä»¥ä¸Šä¸¤ç§æƒ…å†µ, "ä»–ä¸ºè‡ªå·±ç†å‘"å½“ä¸”ä»…å½“"ä»–ä¸ä¸ºè‡ªå·±ç†å‘", è¿™æˆä¸ºäº†ä¸€ä¸ªæ‚–è®º.

ç†å‘å¸ˆæ‚–è®ºåœ¨å¾ˆå¤šé¢†åŸŸæœ‰é‡è¦çš„åº”ç”¨, æ¯”å¦‚ç½—ç´ åˆ©ç”¨ç†å‘å¸ˆæ‚–è®ºå‘ç°äº†é›†åˆè®ºçš„ç¼ºé™·, åœ¨å½“æ—¶å­¦æœ¯ç•Œå¼•èµ·äº†æå¤§éœ‡åŠ¨. åœ¨è¿™é‡Œ, æˆ‘ä»¬è¦ç”¨ç†å‘å¸ˆæ‚–è®ºåˆ†æ[åœæœºé—®é¢˜](https://zhida.zhihu.com/search?content_id=59575968&content_type=Answer&match_order=1&q=%E5%81%9C%E6%9C%BA%E9%97%AE%E9%A2%98&zhida_source=entity).


**åœæœºé—®é¢˜**
å½“æˆ‘ä»¬å†™ä»£ç è°ƒè¯•çš„æ—¶å€™, æœ‰æ—¶ä¼šé‡åˆ°è¿™æ ·ä¸€ç§æƒ…å†µ: ç­‰äº†å¾ˆä¹…, ç¨‹åºè¿˜ä¸€ç›´åœ¨è¿è¡Œ. æˆ‘ä»¬ä¸çŸ¥é“æ˜¯ä»£ç åœ¨æ­£å¸¸è¿è¡Œåªæ˜¯è¿è¡Œæ—¶é—´æ¯”è¾ƒä¹…, è¿˜æ˜¯ä»£ç å†™çš„æœ‰é—®é¢˜(æ¯”å¦‚å†™äº†æ­»å¾ªç¯)å¯¼è‡´ç¨‹åºæ ¹æœ¬ä¸ä¼šåœæ­¢. è¿™æ—¶å€™æˆ‘ä»¬æƒ³, å¦‚æœèƒ½æœ‰ä¸ªå·¥å…·èƒ½ä¸ºæˆ‘ä»¬åˆ¤æ–­æˆ‘ä»¬å†™çš„ä»£ç çš„è¿è¡Œæ—¶é—´å°±å¥½äº†. è¿™å°±æ˜¯åœæœºé—®é¢˜.

ä¸å¤±ä¸€èˆ¬æ€§, å‡è®¾æˆ‘ä»¬æƒ³è¦æµ‹è¯•çš„ä»£ç æ˜¯ä¸€ä¸ªå‡½æ•°

```cpp
void f(char *t);
```

å…¶ä¸­tæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸², æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²è¡¨ç¤ºä»»æ„è¾“å…¥, åŒ…æ‹¬`int`, `double`, åŠå¤åˆæ•°æ®ç±»å‹; å½“fä¸éœ€è¦è¾“å…¥æ—¶, `t`æ˜¯ä¸€ä¸ªç©ºå­—ç¬¦ä¸². åœæœºé—®é¢˜æ˜¯æŒ‡å¯¹ç»™å®šä»»æ„çš„ä¸€ä¸ªå‡½æ•°`f`å’Œè¾“å…¥`t`, åˆ¤æ–­`f`å¯¹`t`æ˜¯å¦ä¼šæ°¸è¿œè¿è¡Œä¸‹å»; å¦‚æœç¨‹åºçš„è¿è¡Œæ—¶é—´æ˜¯æœ‰é™é•¿çš„, æˆ‘ä»¬ç§°`f`å¯¹`t`**åœæœº**.

é—æ†¾çš„æ˜¯, **ä¸å­˜åœ¨**è¿™æ ·çš„ä¸€ä¸ªå·¥å…·ä½¿å¾—å…¶èƒ½åˆ¤æ–­ä»»æ„fçš„åœæœºé—®é¢˜, å³**åœæœºé—®é¢˜ä¸å¯åˆ¤å®š**.

ä»¥ä¸‹æˆ‘ä»¬ç”¨åè¯æ³•è¯æ˜è¿™ä¸ªæ–­è¨€. å‡è®¾å­˜åœ¨è¿™æ ·çš„ä¸€ä¸ªå‡½æ•°å¯ç”¨äºåˆ¤æ–­åœæœºé—®é¢˜

```cpp
bool halts(char *f_code, char *t);
```

å…¶ä¸­`f_code`æ˜¯æˆ‘ä»¬è¦è¿›è¡Œæµ‹è¯•çš„å‡½æ•°fçš„ASCIIæºä»£ç , æˆ‘ä»¬å¯ä»¥è®¤ä¸ºå¯¹`f_code`è¿›è¡Œç¼–è¯‘å¾—åˆ°äº†å‡½æ•°`f`. å½“`f`å¯¹`t`åœæœºæ—¶, `halts(f_code, t)`è¿”å›`true`; å½“`f`å¯¹`t`ä¸åœæœº, `halts(f_code, t)`è¿”å›`false`.

æˆ‘ä»¬æ„é€ è¿™æ ·ä¸€ä¸ªå‡½æ•°

```cpp
void modified_halts(char *f_code) {
  if (halts(f_code, f_code)) {  // å½“halts(f_code, f_code)è¿”å›true
    while (true) { /*empty*/ }  // æ­»å¾ªç¯
  }
  else {                        // å½“halts(f_code, f_code)è¿”å›false
    return;                     // ç«‹å³åœæ­¢è¿è¡Œ
  }
}
```

å³å½“`f`å¯¹`f_code`åœæœºæ—¶, æˆ‘ä»¬è®©`modified_halts`ä¸åœæœº; å½“`f`å¯¹`f_code`ä¸åœæœºæ—¶,`modified_halts`åœæœº.

å‡è®¾`modified_halts`è¿™ä¸ªå‡½æ•°çš„ASCIIæºä»£ç æ˜¯`modified_halts_code`, å¦‚æœæˆ‘ä»¬æŠŠ`modified_halts_code`ä½œä¸º`modified_halts`çš„è¾“å…¥ä¼šæ˜¯ä»€ä¹ˆæƒ…å†µ?

- å¦‚æœ`modified_halts`å¯¹`modified_halts_code`åœæœº, è¯´æ˜`halts(modified_halts_code, modified_halts_code)`è¿”å›`false`, è¯´æ˜`modified_halts`å¯¹`modified_halts_code`ä¸åœæœº;
- å¦‚æœ`modified_halts`å¯¹`modified_halts_code`ä¸åœæœº, è¯´æ˜`halts(modified_halts_code, modified_halts_code)`è¿”å›`true`, è¯´æ˜`modified_halts`å¯¹`modified_halts_code`åœæœº.

ç»¼åˆä»¥ä¸Šä¸¤ç§æƒ…å†µ, "`modified_halts`å¯¹`modified_halts_code`åœæœº"å½“ä¸”ä»…å½“"`modified_halts`å¯¹`modified_halts_code`ä¸åœæœº", è¿™æ˜¯ä¸€ä¸ªçŸ›ç›¾, è¯´æ˜ä¸å­˜åœ¨è¿™æ ·ä¸€ä¸ª`halts`å‡½æ•°å¯ç”¨äºåˆ¤æ–­ä»»æ„å‡½æ•°çš„å¯åœæœºæ€§.

**ä»¥ä¸Šè¿™ä¸ªè¯æ˜åˆ©ç”¨çš„å°±æ˜¯ç†å‘å¸ˆæ‚–è®º, `modified_halts`å‡½æ•°å°±åƒæ˜¯é‚£ä½å…‹é‡Œå…‹å²›å°åŸé‡Œçš„ç†å‘å¸ˆ, ä»–å¯¹å¹¶ä¸”åªå¯¹é‚£äº›ä¸åœæœºçš„å‡½æ•°åœæœº. å½“`modified_halts`å‡½æ•°é¢å¯¹ä»–è‡ªå·±çš„å‡½æ•°ä»£ç æ—¶, å°±åƒç†å‘å¸ˆè¯¥ä¸è¯¥ç»™ä»–è‡ªå·±åˆ®èƒ¡å­ä¸€æ ·, å°†é™·å…¥ä¸¤éš¾å¢ƒåœ°.**


**åœæœºé—®é¢˜çš„æ„ä¹‰**
åœæœºé—®é¢˜çš„æ„ä¹‰åŒ…æ‹¬ä»¥ä¸‹ä¸‰ç‚¹:
1. **è®¡ç®—æœºçš„è®¡ç®—èƒ½åŠ›**. éšç€ç”µå­æŠ€æœ¯å’Œè®¡ç®—æœºæŠ€æœ¯çš„å‘å±•, è®¡ç®—æœºçš„å­˜å‚¨å’Œè®¡ç®—èƒ½åŠ›ä¸æ—¥ä¿±è¿›, æœ‰äº›ä»¥å‰çœ‹èµ·æ¥ä¸å¯è¡Œçš„é—®é¢˜ç°åœ¨å·²ç»å¯ä»¥è½»æ¾åœ°è§£å†³. ä½†æ˜¯ä¸æ˜¯å½“å­˜å‚¨å’Œè®¡ç®—èƒ½åŠ›å¤§åˆ°æ— é™çš„æ—¶å€™, æˆ‘ä»¬å¯ä»¥è§£å†³ä»»ä½•é—®é¢˜? åœæœºé—®é¢˜ç»™å‡ºäº†å¦å®šçš„ç­”æ¡ˆ, å³ä¸ç®¡è®¡ç®—æœºçš„å­˜å‚¨å’Œè®¡ç®—èƒ½åŠ›æœ‰å¤šå¼º, åœæœºé—®é¢˜éƒ½æ— æ³•è§£å†³.
2. **ä¸åŒè¯­è¨€, ä¸åŒè®¡ç®—è®¾å¤‡çš„è®¡ç®—èƒ½åŠ›.** 1936å¹´Alan Turingè®¾è®¡å‡ºä¸€ç§å‡æƒ³çš„è®¡ç®—è®¾å¤‡ç§°ä¸º **[é€šç”¨å›¾çµæœº](https://zhida.zhihu.com/search?content_id=59575968&content_type=Answer&match_order=1&q=%E9%80%9A%E7%94%A8%E5%9B%BE%E7%81%B5%E6%9C%BA&zhida_source=entity)**,  **[Church-Turingè®ºé¢˜](https://zhida.zhihu.com/search?content_id=59575968&content_type=Answer&match_order=1&q=Church-Turing%E8%AE%BA%E9%A2%98&zhida_source=entity)** æŒ‡å‡ºå¦‚æœä¸€ä¸ªå‡½æ•°æ˜¯å¯è®¡ç®—çš„, é‚£ä¹ˆè¿™ä¸ªå‡½æ•°å¯ä»¥ç”¨å›¾çµæœºç¼–ç¨‹å»è®¡ç®—å®ƒ. è€Œåœæœºé—®é¢˜å°±æ˜¯ä¸å¯è®¡ç®—çš„. è™½ç„¶ç°åœ¨å¸‚é¢ä¸Šæœ‰å¾ˆå¤šè¯­è¨€, çœ‹ä¸Šå»Cèƒ½ç›´æ¥æ“ä½œåº•å±‚, Cçš„è®¡ç®—èƒ½åŠ›è¦æ¯”Java, Pythonè¿™æ ·çš„è¯­è¨€æ›´å¼º, ä½†æ˜¯ç°åœ¨æ‰€æœ‰çš„è¯­è¨€éƒ½æ˜¯**Turingå®Œå¤‡**çš„, æ„æ€æ˜¯æŒ‡è¿™ä¸ªè¯­è¨€å¯ä»¥è¢«ç”¨æ¥æ¨¡æ‹Ÿä¸€å°é€šç”¨å›¾çµæœº. å› æ­¤, ä»»ä½•å¯ä»¥ç”¨Cç¼–ç¨‹å‡ºæ¥çš„åŒæ ·ä¹Ÿå¯ä»¥ç”¨Java, Pythonè¿™æ ·çš„è¯­è¨€ç¼–ç¨‹å‡ºæ¥, æ‰€æœ‰è¯­è¨€åœ¨è®¡ç®—èƒ½åŠ›ä¸Šç­‰ä»·.
3. **ä¸å­˜åœ¨ä¸€ä¸ªå®Œç¾çš„å·¥å…·å¯ä»¥æ£€æµ‹ä»£ç çš„è¿è¡Œæ—¶æ€§è´¨**. æ¯”å¦‚è¯´, è®¸å¤šç¼–è¯‘å™¨éƒ½å¯ä»¥åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­å¯¹ä»£ç è¿›è¡Œé™æ€ç±»å‹æ£€æŸ¥, ä»¥ç¡®ä¿ä»£ç ä¸ä¼šå‡ºç°è¿è¡Œæ—¶çš„ç±»å‹é”™è¯¯. æˆ‘ä»¬åŒæ ·å¯ä»¥ç”¨ç†å‘å¸ˆæ‚–è®ºè¯æ˜, ä¸å­˜åœ¨å®Œç¾çš„ç±»å‹æ£€æŸ¥å·¥å…·, å³ä¸€å®šä¼šå­˜åœ¨ä¸€äº›ä»£ç , ç±»å‹æ£€æŸ¥å·¥å…·ä¼šè®¤ä¸ºå®ƒæœ‰é—®é¢˜, è€Œå®é™…è¿™ä¸ªä»£ç ä¸ä¼šå‡ºç°è¿è¡Œæ—¶çš„ç±»å‹é”™è¯¯. å¯¹åœæœºé—®é¢˜çš„ç ”ç©¶å¯ä»¥ä½œä¸ºæˆ‘ä»¬åšå®é™…é—®é¢˜çš„æŒ‡å¯¼.

**å‚è€ƒæ–‡çŒ®**
[1]. Alan Turing. On computable numbers, with an application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, Series 2, Volume 42 (1937), pp 230â€“265.
[2]. Robert Soare. Turing oracle machines, online computing, and three displacements in computability theory. Annals of Pure and Applied Logic 160.3 (2009): 368-399.
[3]. Eric Lehman, Thomson Leighton, and Albert Meyer. Mathematics for Computer Science (2017 version). MIT. 2017.
[4]. Udi Aharoni. Zuto: The Adventures of a Computer Virus. CreateSpace Independent Publishing Platform. 2012.
[5]. å®‹æ–¹æ•. è®¡ç®—æ¨¡å‹å¯¼å¼•. é«˜ç­‰æ•™è‚²å‡ºç‰ˆç¤¾. 20121

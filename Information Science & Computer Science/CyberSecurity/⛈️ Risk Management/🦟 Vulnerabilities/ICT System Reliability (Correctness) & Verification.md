# ICT System Reliability (Correctness) & Verification

[TOC]



## Res
### Related Topics
‚Üó [Cryptology & Secure Communication](../../üö¨%20Cryptology%20&%20Secure%20Communication/Cryptology%20&%20Secure%20Communication.md)
‚Üó [Reliable Data Transfer (RDT)](../../../üîë%20CS%20Core/üèéÔ∏è%20Computer%20Networking%20and%20Communication/üìå%20Computer%20Networking%20Basics%20(Protocol%20Part)/Reliable%20Data%20Transfer%20(RDT)/Reliable%20Data%20Transfer%20(RDT).md)

‚Üó [Formal Semantics and Programming Language](../../../üîë%20CS%20Core/üë©‚Äçüíª%20Computer%20Languages%20&%20Programming%20Methodology/üê¢%20Programming%20Language%20Theory%20(PLT)/Formal%20Semantics%20and%20Programming%20Language.md)
‚Üó [Formal Methods & Formal Verification (FV)](üç¶%20Software%20Security/ü™Ü%20Software%20Analysis%20&%20Binary%20Engineering/üìå%20Software%20Analysis%20Basics%20Methodologies/üôá‚Äç‚ôÇÔ∏è%20Formal%20Methods%20&%20Formal%20Verification%20(FV)/Formal%20Methods%20&%20Formal%20Verification%20(FV).md)

‚Üó [Software Quality Assurance (SQA)](../../../Software%20Engineering/üé≠%20Software%20Quality%20Assurance%20(SQA)/Software%20Quality%20Assurance%20(SQA).md)


### Other Resources



## Intro
> üìñ Principles of Model Checking, Christel Baier and Joost-Pieter Katoen

System verification techniques are being applied to the design of ICT systems in a more reliable way. Briefly, system verification is used to establish that the design or product under consideration possesses certain properties. The properties to be validated can be quite elementary, e.g., a system should never be able to reach a situation in which no progress can be made (a deadlock scenario), and are mostly obtained from the system‚Äôs specification. This specification prescribes what the system has to do and what not, and thus constitutes the basis for any verification activity. A defect is found once the system does not fulfill one of the specification‚Äôs properties. The system is considered to be ‚Äúcorrect‚Äù whenever it satisfies all properties obtained from its specification. So correctness is always relative to a specification, and is not an absolute property of a system. A schematic view of verification is depicted in Figure 1.2.

![|500](../../../../Assets/Pics/Screenshot%202025-08-29%20at%2012.59.44.png)

**Software Verification**: ‚Üó [Software Quality Assurance (SQA)](../../../Software%20Engineering/üé≠%20Software%20Quality%20Assurance%20(SQA)/Software%20Quality%20Assurance%20(SQA).md)
- *Peer reviewing* (‚Üó [Code Review](../üê∫%20Risk%20Countermeasures%20&%20Security%20Control/Security%20Audit%20&%20Security%20Audit%20Trail/Code%20Review.md)) and *software testing* (‚Üó [Software Testing](../../../Software%20Engineering/üé≠%20Software%20Quality%20Assurance%20(SQA)/üß™%20Software%20Testing/Software%20Testing.md)) are the major software verification techniques used in practice.
- ‚Üó [Formal Methods & Formal Verification (FV)](üç¶%20Software%20Security/ü™Ü%20Software%20Analysis%20&%20Binary%20Engineering/üìå%20Software%20Analysis%20Basics%20Methodologies/üôá‚Äç‚ôÇÔ∏è%20Formal%20Methods%20&%20Formal%20Verification%20(FV)/Formal%20Methods%20&%20Formal%20Verification%20(FV).md)

**Hardware verification**: *Emulation*, *simulation*, and *structural analysis* are the major techniques used in hardware verification.
- **Structural analysis** comprises several specific techniques such as synthesis, timing analysis, and equivalence checking that are not described in further detail here.
- **Emulation** is a kind of testing. A reconfigurable generic hardware system (the emulator) is configured such that it behaves like the circuit under consideration and is then extensively tested. As with software testing, emulation amounts to providing a set of stimuli to the circuit and comparing the generated output with the expected output as laid down in the chip specification. To fully test the circuit, all possible input combinations in every possible system state should be examined. This is impractical and the number of tests needs to be reduced significantly, yielding potential undiscovered errors.
- With **simulation**, a model of the circuit at hand is constructed and simulated. Models are typically provided using hardware description languages such as Verilog or VHDL that are both standardized by IEEE. Based on stimuli, execution paths of the chip model are examined using a simulator. These stimuli may be provided by a user, or by automated means such as a random generator. A mismatch between the simulator‚Äôs output and the output described in the specification determines the presence of errors. Simulation is like testing, but is applied to models. It suÔ¨Äers from the same limitations, though: the number of scenarios to be checked in a model to get full confidence goes beyond any reasonable subset of scenarios that can be examined in practice.
	- Simulation is the most popular hardware verification technique and is used in various design stages, e.g., at register-transfer level, gate and transistor level. Besides these error detection techniques, hardware testing is needed to find fabrication faults resulting from layout defects in the fabrication process.

**System Verification**:
About 50% of all defects are introduced during programming, the phase in which actual coding takes place. Whereas just 15% of all errors are detected in the initial design stages, most errors are found during testing. At the start of unit testing, which is oriented to discovering defects in the individual software modules that make up the system, a defect density of about 20 defects per 1000 lines of (uncommented) code is typical. This has been reduced to about 6 defects per 1000 code lines at the start of system testing, where a collection of such modules that constitutes a real product is tested. On launching a new software release, the typical accepted software defect density is about one defect per 1000 lines of code lines1.

Errors are typically concentrated in a few software modules ‚Äì about half of the modules are defect free, and about 80% of the defects arise in a small fraction (about 20%) of the modules ‚Äì and often occur when interfacing modules. The repair of errors that are detected prior to testing can be done rather economically. The repair cost significantly increases from about $ 1000 (per error repair) in unit testing to a maximum of about $ 12,500 when the defect is demonstrated during system operation only. It is of vital importance to seek techniques that find defects as early as possible in the software design process: the costs to repair them are substantially lower, and their influence on the rest of the design is less substantial.

![](../../../../Assets/Pics/Screenshot%202025-08-29%20at%2013.08.12.png)



## Ref

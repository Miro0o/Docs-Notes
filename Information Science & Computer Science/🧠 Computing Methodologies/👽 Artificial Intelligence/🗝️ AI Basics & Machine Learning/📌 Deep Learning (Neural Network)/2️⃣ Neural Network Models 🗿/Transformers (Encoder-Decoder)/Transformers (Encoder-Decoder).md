# Transformers (Encoder-Decoder)

[TOC]



## Res
### Related Topics
â†— [LLM (Large Language Model)](../../../../Natural%20Language%20Processing%20(NLP)/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/LLM%20(Large%20Language%20Model).md)


### Learning Resources
https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=AUDMGwyz7-yL33Xd
Neural networks | 3Blue1Brown
- [But what is a neural network? | Deep learning chapter 1](https://youtu.be/aircAruvnKk?si=RiyEviyfGbC8YwS0)
- [Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://youtu.be/IHZwWFHWa-w?si=DqZgN_65JZfHX-81)
- [Backpropagation, intuitively | Deep Learning Chapter 3](https://youtu.be/Ilg3gGewQ5U?si=yYl6Vi6Sb-NxWbh5)
- [Backpropagation calculus | Deep Learning Chapter 4](https://youtu.be/tIeHLnjs5U8?si=w84SrOkyDnMwKSk7)
- [Large Language Models explained briefly](https://youtu.be/LPZh9BOjkQs?si=7CRyWTVnx3BIGQGy)
- [Transformers, the tech behind LLMs | Deep Learning Chapter 5](https://youtu.be/wjZofJX0v4M?si=cLC36CWJiJPKQJgT)
	- ã€ã€å®˜æ–¹åŒè¯­ã€‘GPTæ˜¯ä»€ä¹ˆï¼Ÿç›´è§‚è§£é‡ŠTransformer | æ·±åº¦å­¦ä¹ ç¬¬5ç« -å“”å“©å“”å“©ã€‘ https://b23.tv/rcO76mO
- [Attention in transformers, step-by-step | Deep Learning Chapter 6](https://youtu.be/eMlx5fFNoYc?si=UqpVj1vDxOtWAnlc)
	- ã€ã€å®˜æ–¹åŒè¯­ã€‘ç›´è§‚è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformerçš„æ ¸å¿ƒ | ã€æ·±åº¦å­¦ä¹ ç¬¬6ç« ã€‘-å“”å“©å“”å“©ã€‘ https://b23.tv/f0udg4P
- [How might LLMs store facts | Deep Learning Chapter 7](https://youtu.be/9-Jl0dxWQs8?si=jJPuNPfLV6AtWNJa)

ğŸ‘ https://poloclub.github.io/transformer-explainer/ (This is a soo good explaination!)
![](../../../../../../../Assets/Pics/Screenshot%202025-09-04%20at%2020.14.39.png)
Transformer Explainer
- Transformer Explainer features a live GPT-2 (small) model running directly in the browser. This model is derived from the PyTorch implementation of GPT by Andrej Karpathy'sÂ [nanoGPT project](https://github.com/karpathy/nanoGPT "Github")Â and has been converted toÂ [ONNX Runtime](https://onnxruntime.ai/ "ONNX")Â for seamless in-browser execution. The interface is built using JavaScript, withÂ [Svelte](https://kit.svelte.dev/ "Svelte")Â as a front-end framework andÂ [D3.js](https://d3js.org/ "D3")Â for creating dynamic visualizations. Numerical values are updated live following the user input.
- Transformer Explainer was created byÂ [Aeree Cho](https://aereeeee.github.io/),Â [Grace C. Kim](https://www.linkedin.com/in/chaeyeonggracekim/),Â [Alexander Karpekov](https://alexkarpekov.com/),Â [Alec Helbling](https://alechelbling.com/),Â [Jay Wang](https://zijie.wang/),Â [Seongmin Lee](https://seongmin.xyz/),Â [Benjamin Hoover](https://bhoov.com/), andÂ [Polo Chau](https://poloclub.github.io/polochau/)Â at the Georgia Institute of Technology.



## Intro



## Embedding



## Attention



## Probabilities



## Ref

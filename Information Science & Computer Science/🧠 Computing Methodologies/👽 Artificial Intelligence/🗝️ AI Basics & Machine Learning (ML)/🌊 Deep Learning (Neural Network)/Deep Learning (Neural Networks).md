# Deep Learning (Neural Network)

[TOC]



## Res
### Related Topics
â†— [Neural Network Models](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/Neural%20Network%20Models.md)
â†— [LLM (Large Language Model)](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/LLM%20(Large%20Language%20Model).md)

â†— [Information Theory](../../../../ğŸ§®%20Mathematics/ğŸ§%20Information%20Theory/Information%20Theory.md)
â†— [Linear Algebra](../../../../ğŸ§®%20Mathematics/ğŸ§Š%20Algebra/ğŸƒ%20Algebraic%20Structure%20&%20Abstract%20Algebra%20&%20Modern%20Algebra/Module-Like%20Algebraic%20Structure/Linear%20Algebra/Linear%20Algebra.md)
â†— [Probabilities & Statistics](../../../../ğŸ§®%20Mathematics/ğŸ“%20Measures%20(Measure%20Theory)/ğŸ“Š%20Probabilities%20&%20Statistics/Probabilities%20&%20Statistics.md)
â†— [Analytical Mathematics](../../../../ğŸ§®%20Mathematics/Analytical%20Mathematics/Analytical%20Mathematics.md)


### Learning Resource
>  More on machine learning go to â†—ï¸ [AI Basics & Machine Learning (ML)](../AI%20Basics%20&%20Machine%20Learning%20(ML).md)

åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ , ææ²
ğŸ  https://zh.d2l.ai/index.html (ZH)
ğŸ  https://d2l.ai/index.html (EN)
ğŸš§ https://github.com/d2l-ai/d2l-en (EN)
ğŸš§ https://github.com/d2l-ai/d2l-zh (ZH)
ğŸ‘¥ https://discuss.d2l.ai/c/chinese-version/16
ğŸ¬ã€è·Ÿç€ææ²ã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‘è¯¾ç¨‹ï¼Œå¤§ä½¬äº²æˆå…¨æ–¹é¢è§£è¯»â€œèŠ±ä¹¦â€ï¼Œå¸¦ä½ ä»å…¥é—¨åˆ°ç²¾é€šï¼ˆäººå·¥æ™ºèƒ½/æ·±åº¦å­¦ä¹ /è®¡ç®—æœºè§†è§‰/å›¾åƒå¤„ç†ï¼‰ã€‘ https://www.bilibili.com/video/BV1QP411j7jB/?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d
- é¢å‘ä¸­æ–‡è¯»è€…çš„èƒ½è¿è¡Œã€å¯è®¨è®ºçš„æ·±åº¦å­¦ä¹ æ•™ç§‘ä¹¦
- å« PyTorchã€NumPy/MXNetã€TensorFlow å’Œ PaddlePaddle å®ç°
- è¢«å…¨çƒ 60 å¤šä¸ªå›½å®¶ 400 å¤šæ‰€å¤§å­¦ç”¨äºæ•™å­¦

https://hrl.boyuai.com/chapter/intro
æœ¬ä¹¦ä½œè€…åœ¨ä¸Šæµ·äº¤é€šå¤§å­¦è‡´è¿œå­¦é™¢å’Œç”µå­ä¿¡æ¯ä¸ç”µæ°”å·¥ç¨‹å­¦é™¢ä¸ºå¤§ä¸‰æœ¬ç§‘ç”Ÿå¼€è®¾å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ã€‚ç›®å‰ä¸¤ä¸ªå­¦é™¢çš„å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹åœ¨å…¶åŸ¹å…»æ–¹æ¡ˆä¸­çš†ä¸º 2 å­¦åˆ†ï¼ŒåŒ…å«äº†æ‰€æœ‰æˆè¯¾å’Œå®éªŒçš„å­¦æ—¶ã€‚åœ¨æˆè¯¾å’Œæ‰¹æ”¹å­¦ç”Ÿçš„è¯¾ç¨‹ä½œä¸šçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°å¼ºåŒ–å­¦ä¹ å¯¹äºå­¦ç”Ÿå’Œè€å¸ˆæ¥è¯´éƒ½æ˜¯ä¸€ä¸ªè¾ƒéš¾ç§‘ç›®ã€‚å¯¹äºå­¦ç”Ÿï¼Œå¼ºåŒ–å­¦ä¹ çš„ç†è®ºéƒ¨åˆ†å±äºæœºå™¨å­¦ä¹ å¤§ç§‘ç›®ä¸­è¿›é˜¶éƒ¨åˆ†å†…å®¹ï¼Œæ¶‰åŠåˆ°çš„æ•°å­¦å†…å®¹æ¯”ä¸€èˆ¬æœ‰ç›‘ç£å­¦ä¹ æ›´åŠ å¤æ‚ï¼Œè€Œå¯¹è¿™äº›å†…å®¹çš„çœŸæ­£ç†è§£ç¦»ä¸å¼€ç¼–ç¨‹å®éªŒï¼Œæ²¡æœ‰ç¬¬ä¸€æ‰‹çš„ç¼–ç¨‹å®ç°å’Œè°ƒè¯•ç»éªŒï¼Œå¾ˆå¤šå¼ºåŒ–å­¦ä¹ çš„åŸç†å°±æ— æ³•çœŸåˆ‡ä½“ä¼šã€‚æ€»å¾—æ¥è¯´ï¼Œå¯¹å¼ºåŒ–å­¦ä¹ æŠ€æœ¯çš„æ‰å®æŒæ¡ç¦»ä¸å¼€åŠ¨æ‰‹å®è·µï¼Œè€Œå¸‚é¢ä¸Šç›®å‰å°šæœªæœ‰è¾ƒä¸ºæƒå¨çš„é›†å¼ºåŒ–å­¦ä¹ åŸç†å’ŒåŠ¨æ‰‹å®è·µäºä¸€ä½“çš„ä¹¦ç±ã€‚
åŸºäºåœ¨å¼ºåŒ–å­¦ä¹ ç ”ç©¶å’Œæ•™å­¦ä¸­çš„æµ…è–„ç»éªŒï¼Œæˆ‘ä»¬æ¨å‡ºè¿™æœ¬ã€ŠåŠ¨æ‰‹å­¦å¼ºåŒ–å­¦ä¹ ã€‹ï¼Œæ—¨åœ¨æ¢ç´¢ä¸€ç§æ›´å¥½çš„å¼ºåŒ–å­¦ä¹ çš„æ•™å­¦æ–¹å¼ï¼Œä¸ºä¸­å›½å¼ºåŒ–å­¦ä¹ çš„äººæ‰åŸ¹å…»è´¡çŒ®ä¸€ä»½åŠ›é‡ã€‚ä¹¦ä¸­éš¾å…æœ‰é”™è°¬ä¹‹å¤„ï¼Œè¿˜æœ›å¹¿å¤§è¯»è€…ä¸åæŒ‡æ­£ï¼Œæˆ‘ä»¬æ„Ÿæ¿€ä¸å°½ã€‚

ğŸ« å®ç”¨æœºå™¨å­¦ä¹  [CS 329P Practical Machine Learning](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/Stanford/CS%20329P%20Practical%20Machine%20Learning/CS%20329P%20Practical%20Machine%20Learning.md)
ğŸ« [CS50's Introduction to AI with Python](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/Harvard/CS50's%20Introduction%20to%20AI%20with%20Python/CS50's%20Introduction%20to%20AI%20with%20Python.md)
ğŸ« [CS188 Introduction to Artificial Intelligence](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/UC%20Berkeley/CS188%20Introduction%20to%20Artificial%20Intelligence/CS188%20Introduction%20to%20Artificial%20Intelligence.md)
ğŸ« [CS 231n Deep Learning for Computer Vision](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/Stanford/CS%20231n%20Deep%20Learning%20for%20Computer%20Vision/CS%20231n%20Deep%20Learning%20for%20Computer%20Vision.md)
ğŸ« https://cs230.stanford.edu

ğŸ“– èŠ±ä¹¦ 
https://www.deeplearningbook.org èŠ±ä¹¦å®˜ç½‘  
https://github.com/exacity/deeplearningbook-chinese èŠ±ä¹¦ä¸­æ–‡ç‰ˆç¿»è¯‘  
https://github.com/MingchaoZhu/DeepLearning èŠ±ä¹¦åŸç†æ¨å¯¼åŠä»£ç å®ç°  
https://zhuanlan.zhihu.com/p/38431213 çŸ¥ä¹èŠ±ä¹¦å„ç« ç¬”è®°

ğŸ”¥ ğŸ“„ https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE
Papers must know to understand the world of deep learning & AIGC

[Practical Deep Learning for Coders](https://course.fast.ai/) course fromÂ [fast.ai](https://www.fast.ai/)
This course is extremely practical and oriented in a top-down manner, meaning that you learn how to implement ideas in code and use all the relevant tools first, then dig deeper into the details afterwards to understand how everything works. If youâ€™re new to the space and want to quickly get a working understanding of AI-related tools, how to use them, and how they work, start with these videos.

ğŸ‘ ğŸ‘ https://www.byhand.ai/
AI by Hand

https://www.fast.ai/
- **Courses**:Â [Practical Deep Learning for Coders](https://course.fast.ai/);Â [From Deep Learning Foundations to Stable Diffusion](https://course.fast.ai/Lessons/part2.html)
- **Software**:Â [fastai for PyTorch](https://docs.fast.ai/);Â [nbdev](https://nbdev.fast.ai/)
- **Book**:Â [Practical Deep Learning for Coders with fastai and PyTorch](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527)
- **In the news**:Â [The Economist](https://www.economist.com/business/2018/10/25/new-schemes-teach-the-masses-to-build-ai);Â [The New York Times](https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html);Â [MIT Tech Review](https://www.technologyreview.com/s/611858/small-team-of-ai-coders-beats-googles-code/)

https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=AUDMGwyz7-yL33Xd
Neural networks | 3Blue1Brown
- [But what is a neural network? | Deep learning chapter 1](https://youtu.be/aircAruvnKk?si=RiyEviyfGbC8YwS0)
- [Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://youtu.be/IHZwWFHWa-w?si=DqZgN_65JZfHX-81)
- [Backpropagation, intuitively | Deep Learning Chapter 3](https://youtu.be/Ilg3gGewQ5U?si=yYl6Vi6Sb-NxWbh5)
- [Backpropagation calculus | Deep Learning Chapter 4](https://youtu.be/tIeHLnjs5U8?si=w84SrOkyDnMwKSk7)
- [Large Language Models explained briefly](https://youtu.be/LPZh9BOjkQs?si=7CRyWTVnx3BIGQGy)
- [Transformers, the tech behind LLMs | Deep Learning Chapter 5](https://youtu.be/wjZofJX0v4M?si=cLC36CWJiJPKQJgT)
	- ã€ã€å®˜æ–¹åŒè¯­ã€‘GPTæ˜¯ä»€ä¹ˆï¼Ÿç›´è§‚è§£é‡ŠTransformer | æ·±åº¦å­¦ä¹ ç¬¬5ç« -å“”å“©å“”å“©ã€‘ https://b23.tv/rcO76mO
- [Attention in transformers, step-by-step | Deep Learning Chapter 6](https://youtu.be/eMlx5fFNoYc?si=UqpVj1vDxOtWAnlc)
	- ã€ã€å®˜æ–¹åŒè¯­ã€‘ç›´è§‚è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformerçš„æ ¸å¿ƒ | ã€æ·±åº¦å­¦ä¹ ç¬¬6ç« ã€‘-å“”å“©å“”å“©ã€‘ https://b23.tv/f0udg4P
- [How might LLMs store facts | Deep Learning Chapter 7](https://youtu.be/9-Jl0dxWQs8?si=jJPuNPfLV6AtWNJa)

Michael Nielsen
Neural Networks and Deep Learning

https://distill.pub/

https://colah.github.io/

https://www.mit.edu/~amidi/
https://stanford.edu/~shervine/
- [15.003 â€• Data Science Tools](https://www.mit.edu/~amidi/teaching/data-science-tools/)
- [15.003 - Modeling](https://www.mit.edu/~amidi/teaching/modeling/)
- [CS 221 â€• Artificial Intelligence](https://stanford.edu/~shervine/teaching/cs-221/)
- [CS 229 â€• Machine Learning](https://stanford.edu/~shervine/teaching/cs-229/)
- [CS 230 â€• Deep Learning](https://stanford.edu/~shervine/teaching/cs-230/)
![](../../../../../Assets/Pics/Screenshot%202025-10-05%20at%2023.42.44.png)



## Intro: Neural Network
### Neuron, and The Connection of Information
![computing.excalidraw | 800](../../../../../Assets/Illustrations/Computer%20Science%20Philosophy/computing.excalidraw.md)

![|600](../../../../../Assets/Pics/Screenshot%202025-09-04%20at%2020.19.48.png)
<small><a>https://youtu.be/aircAruvnKk?si=RiyEviyfGbC8YwS0</a></small>

Features in data (æ•°æ®ç‰¹å¾): such **connections** between **informations** that leads to some semantic interpretation. ğŸ¤”


### Neural Network / Deep Network?
- **Neural Networks**: Slow learning, potentially very powerful, can learn very complex patterns. Can be prone to overfitting due to high density of the parameters.
- **Deep Networks**: Very large complex (neural) networks, but made up of many often heterogeneous types of networks that try to simplify the inputs, so that we can use a relatively small dense network to perform final decisions.


### The Technical Evolution of Neural Networks
â†— [The Development History of AI / ğŸ‘‰ Big Data, Deep Learning, AGI (2005â€“2017)](../The%20Development%20History%20of%20AI.md#ğŸ‘‰%20Big%20Data,%20Deep%20Learning,%20AGI%20(2005â€“2017))
â†— [The Development History of AI /ğŸ‘‰ From NLP to AGI: Boom of LLM (2017~)](../The%20Development%20History%20of%20AI.md#ğŸ‘‰%20From%20NLP%20to%20AGI:%20Boom%20of%20LLM%20(2017~))
â†— [Natural Language Processing (NLP) /ğŸ“œ A Brief History of The Technical Evolution Of Language Models](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics.md#ğŸ“œ%20A%20Brief%20History%20of%20The%20Technical%20Evolution%20Of%20Language%20Models)
â†— [LLM (Large Language Model) /â­ LLM Milestone Papers](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/LLM%20(Large%20Language%20Model).md#â­%20LLM%20Milestone%20Papers)

![](../../../../../Assets/Pics/Screenshot%202025-09-01%20at%2010.56.49.png)
<small>
Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang, X., Liu, Z., â€¦ Wen, J.-R. (2025). A Survey of Large Language Models (arXiv:2303.18223). arXiv. <br><a>https://doi.org/10.48550/arXiv.2303.18223</a></small>



## Understanding Neural Networks and Deep Learning
https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=AUDMGwyz7-yL33Xd
Neural networks | 3Blue1Brown
- [But what is a neural network? | Deep learning chapter 1](https://youtu.be/aircAruvnKk?si=RiyEviyfGbC8YwS0)
- [Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://youtu.be/IHZwWFHWa-w?si=DqZgN_65JZfHX-81)
- [Backpropagation, intuitively | Deep Learning Chapter 3](https://youtu.be/Ilg3gGewQ5U?si=yYl6Vi6Sb-NxWbh5)
- [Backpropagation calculus | Deep Learning Chapter 4](https://youtu.be/tIeHLnjs5U8?si=w84SrOkyDnMwKSk7)
- [Large Language Models explained briefly](https://youtu.be/LPZh9BOjkQs?si=7CRyWTVnx3BIGQGy)
- [Transformers, the tech behind LLMs | Deep Learning Chapter 5](https://youtu.be/wjZofJX0v4M?si=cLC36CWJiJPKQJgT)
- [Attention in transformers, step-by-step | Deep Learning Chapter 6](https://youtu.be/eMlx5fFNoYc?si=UqpVj1vDxOtWAnlc)
- [How might LLMs store facts | Deep Learning Chapter 7](https://youtu.be/9-Jl0dxWQs8?si=jJPuNPfLV6AtWNJa)


### Neural Network Basics
1. Linear Perceptrons
	1. XOR Problems
2. MLP (Multi-Layer Perceptron)
#### MLP (Multi Layer Perceptrons)
![](../../../../../../../../Assets/Pics/Screenshot%202023-01-29%20at%2012.54.02%20AM.png)
<small>fully connected, dense layer</small>
#### Gradient Descent & Backpropagation
https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=AUDMGwyz7-yL33Xd
Neural networks | 3Blue1Brown
- [But what is a neural network? | Deep learning chapter 1](https://youtu.be/aircAruvnKk?si=RiyEviyfGbC8YwS0)
- [Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://youtu.be/IHZwWFHWa-w?si=DqZgN_65JZfHX-81)
- [Backpropagation, intuitively | Deep Learning Chapter 3](https://youtu.be/Ilg3gGewQ5U?si=yYl6Vi6Sb-NxWbh5)
- [Backpropagation calculus | Deep Learning Chapter 4](https://youtu.be/tIeHLnjs5U8?si=w84SrOkyDnMwKSk7)

ğŸ¬ https://youtu.be/VMj-3S1tku0?si=GljktCky9TZOrXMF
This is the most step-by-step spelled-out explanation of backpropagation and training of neural networks. It only assumes basic knowledge of Python and a vague recollection of calculus from high school. Links:
- micrograd on github: [https://github.com/karpathy/micrograd](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblpTMk9PQTViUGt2RElMcEJNWmRTdkhUNnFRZ3xBQ3Jtc0ttV01BaEUtdW04bHF3UTlXNFQycWFiUUFjWGZ1TDZBWnNCWlA1WHpQckxmWE5rVHRvejNMWnFtd0k1M3JQRTN0RUhJRE5XSkRWeEVxeHNIc1VaTExVaXdxVVVUSUkwZEVJaXB3X3h4b0ZQNUJIR3dTUQ&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmicrograd&v=VMj-3S1tku0)
- jupyter notebooks I built in this video: [https://github.com/karpathy/nn-zero-t...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHFxeGdRcGVWdXhjLV9RbHQyZm94djdLYm4tUXxBQ3Jtc0tuS1JKOFBIcTRadWtVY1BBZFUtY3d6U09iZ29FcjR4R2c2MzgtSlRjZWlnOEkxUFUtVUlZaTNXSkFRUXJSaXBxNkVER3NSbTMzbG9iQnBuckl5WWNWU1hOUTdwSGtuNmNLbUhUNWg1c1dWanpCYkZNUQ&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Ftree%2Fmaster%2Flectures%2Fmicrograd&v=VMj-3S1tku0)
- my website: [https://karpathy.ai](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbU9pTktUTXpQLU45U3AzbkZZdUlXUTdZZzdwQXxBQ3Jtc0ttQlU0QmJ3S05XNmJJYWFoa0ZNQmhQMnJUdGhlWG9RcDgtYzR4MUE2amhLLVBRQ2lzTTMyZUxtWG90bTU4a1pPWW9CaGY2dldoRXNweS1Qb3FFMzRsVDZYSVEyV0JoZVJfcE02N2pWVGJIVWVSdDlkNA&q=https%3A%2F%2Fkarpathy.ai%2F&v=VMj-3S1tku0)



### CNN (Convolution Neural Network)
â†— [CNN (Convolutional Neural Network)](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/CNN%20(Convolutional%20Neural%20Network)/CNN%20(Convolutional%20Neural%20Network).md)
- â†— [VGGNet](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/CNN%20(Convolutional%20Neural%20Network)/VGGNet/VGGNet.md)
- â†— [YOLO (You Only Look Once)](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/CNN%20(Convolutional%20Neural%20Network)/YOLO%20(You%20Only%20Look%20Once)/YOLO%20(You%20Only%20Look%20Once).md)
- etc.


### RNN (Recurrent Neural Network)
â†— [RNN (Recurrent Neural Network)](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/RNN%20(Recurrent%20Neural%20Network)/RNN%20(Recurrent%20Neural%20Network).md)
#### LSTM (Long-Short Term Memories)
â†— [LSTM (Long-Short Term Memories)](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/RNN%20(Recurrent%20Neural%20Network)/LSTM%20(Long-Short%20Term%20Memories)/LSTM%20(Long-Short%20Term%20Memories).md)


### Transformer & LLM
â†— [Transformers](2ï¸âƒ£%20Neural%20Network%20Models%20ğŸ—¿/Transformers/Transformers.md)
â†— [LLM (Large Language Model)](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/LLM%20(Large%20Language%20Model).md)
- â†— [OpenAI ChatGPT](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/OpenAI%20ChatGPT.md)
- â†— [Google Gemini](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/Google%20Gemini.md)
- â†— [Anthropic Claude](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/Anthropic%20Claude.md)
- â†— [Meta LLama](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/Meta%20LLama.md)
- â†— [DeepSeek](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/DeepSeek.md)
- â†— [xAI Grok](../../Natural%20Language%20Processing%20(NLP)%20&%20Computational%20Linguistics/ğŸ¦‘%20LLM%20(Large%20Language%20Model)/ğŸªœ%20LLM%20Models%20Guide%20&%20Leaderboard/xAI%20Grok.md)



## NN Hyperparameters



## Ref
[Deep Learning vs. Machine Learning]: https://dzone.com/articles/deep-learning-vs-machine-learning-the-hottest-topi

[What Is the Necessity of Bias in Neural Networks?]: https://www.turing.com/kb/necessity-of-bias-in-neural-networks#components-in-artificial-neural-networks
Components in artificial neural networks:
1.  **Inputs:**Â Theyâ€™re usually represented as features of a dataset which are passed on to a neural network to make predictions.
2.  **Weights:**Â These are the real values associated with the features. They are significant as they tell the importance of each feature which is passed as an input to theÂ [artificial neural network](https://www.turing.com/kb/importance-of-artificial-neural-networks-in-artificial-intelligence).
3.  **Bias:**Â Bias in a neural network is required to shift the activation function across the plane either towards the left or the right. We will cover it in more detail later.
4.  **Summation function:**Â It is defined as the function which sums up the product of the weight and the features with bias.
5.  **Activation function:**Â It is required to add non-linearity to the neural network model

[AAAI2024 | åˆ†äº«10ç¯‡ä¼˜ç§€è®ºæ–‡ï¼Œæ¶‰åŠå›¾ç¥ç»ç½‘ç»œã€å¤§æ¨¡å‹ä¼˜åŒ–ã€è¡¨æ ¼åˆ†æç­‰çƒ­é—¨è¯é¢˜]: https://mp.weixin.qq.com/s/F7X8N_wUyZQNhDtIfHm17Q

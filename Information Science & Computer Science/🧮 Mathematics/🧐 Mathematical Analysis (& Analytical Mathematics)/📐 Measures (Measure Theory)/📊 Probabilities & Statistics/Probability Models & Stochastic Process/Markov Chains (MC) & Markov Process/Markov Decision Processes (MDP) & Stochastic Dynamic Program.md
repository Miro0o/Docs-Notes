# Markov Decision Processes (MDP) & Stochastic Dynamic Program

[TOC]



## Res
### Related Topics


### Other Resources
[FKNP11](https://www.prismmodelchecker.org/bibitem.php?key=FKNP11) (for MDPs)



## Intro
> ðŸ”— https://en.wikipedia.org/wiki/Markov_decision_process

**Markov decision process**Â (**MDP**), also called aÂ [stochastic dynamic program](https://en.wikipedia.org/wiki/Stochastic_dynamic_programming "Stochastic dynamic programming")Â or stochastic control problem, is a model forÂ [sequential decision making](https://en.wikipedia.org/wiki/Sequential_decision_making "Sequential decision making")Â whenÂ [outcomes](https://en.wikipedia.org/wiki/Outcome_\(probability\) "Outcome (probability)")Â are uncertain.

Originating fromÂ [operations research](https://en.wikipedia.org/wiki/Operations_research "Operations research")Â in the 1950s,Â MDPs have since gained recognition in a variety of fields, includingÂ [ecology](https://en.wikipedia.org/wiki/Ecology "Ecology"),Â [economics](https://en.wikipedia.org/wiki/Economics "Economics"),Â [healthcare](https://en.wikipedia.org/wiki/Health_care "Health care"),Â [telecommunications](https://en.wikipedia.org/wiki/Telecommunications "Telecommunications")Â andÂ [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning "Reinforcement learning").Â Reinforcement learning utilizes the MDP framework to model the interaction between a learning agent and its environment. In this framework, the interaction is characterized by states, actions, and rewards. The MDP framework is designed to provide a simplified representation of key elements ofÂ [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence "Artificial intelligence")Â challenges. This modeling framework incorporates the understanding ofÂ [cause and effect](https://en.wikipedia.org/wiki/Causality "Causality"), the management of uncertainty and nondeterminism, and the pursuit of explicit goals.

The name comes from its connection toÂ [Markov chains](https://en.wikipedia.org/wiki/Markov_chain "Markov chain"), a concept developed by the Russian mathematicianÂ [Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov "Andrey Markov"). The "Markov" in "Markov decision process" refers to the underlying structure ofÂ [state transitions](https://en.wikipedia.org/wiki/Transition_system "Transition system")Â that still follow theÂ [Markov property](https://en.wikipedia.org/wiki/Markov_property "Markov property"). The process is called a "decision process" because it involves making decisions that influence these state transitions, extending the concept of a Markov chain into the realm of decision-making under uncertainty.



## Ref

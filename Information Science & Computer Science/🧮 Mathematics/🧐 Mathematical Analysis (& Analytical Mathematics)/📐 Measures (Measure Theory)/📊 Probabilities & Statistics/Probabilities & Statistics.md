# Probabilities  & Statistics

[TOC]



## Res
### Related Topics
â†— [Statistical Learning Theory & ML Types](../../../../ğŸ§ %20Computing%20Methodologies/ğŸ‘½%20Artificial%20Intelligence/ğŸ—ï¸%20AI%20Basics%20&%20Machine%20Learning%20(ML)/ğŸ“Š%20Statistical%20Learning%20Theory%20&%20ML%20Types/Statistical%20Learning%20Theory%20&%20ML%20Types.md)
â†— [Data-Oriented & Human-Centered Technologies](../../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data-Oriented%20&%20Human-Centered%20Technologies.md)
- â†— [Data Science](../../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data%20Science/Data%20Science.md)
- â†— [Data Mining](../../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data%20Science/â›ï¸%20Data%20Mining/Data%20Mining.md)


### Learning Resources
ğŸ« [UCB /CS70 Discrete Math and Probability Theory](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/UC%20Berkeley/CS70%20Discrete%20Math%20and%20Probability%20Theory/CS70%20Discrete%20Math%20and%20Probability%20Theory.md)
ğŸ« [UCB /CS126 Probability Theory](../../../../ğŸ—º%20CS%20Overview/ğŸ’‹%20Intro%20to%20Computer%20Science/ğŸ‘©ğŸ¼â€ğŸ«%20Courses%20of%20Universities/UC%20Berkeley/CS126%20Probability%20Theory/CS126%20Probability%20Theory.md)

ğŸ“– ä½•ä¹¦å…ƒã€Šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ã€‹
- ç¬¬ä¸€ç«  å¤å…¸æ¦‚å‹å’Œæ¦‚ç‡ç©ºé—´
	- 1.1 è¯•éªŒä¸äº‹ä»¶. . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
	- 1.2 å¤å…¸æ¦‚å‹ä¸å‡ ä½•æ¦‚å‹. . . . . . . . . . . . . . . . . . . . . . . 7
		- 1.2.1 å¤å…¸æ¦‚å‹. . . . . . . . . . . . . . . . . . . . . . . . . 7
		- 1.2.2 å‡ ä½•æ¦‚å‹. . . . . . . . . . . . . . . . . . . . . . . . . 14
	- 1.3 æ¦‚ç‡çš„å…¬ç†åŒ–å’ŒåŠ æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . 15
		- 1.3.1 æ¦‚ç‡çš„å…¬ç†åŒ–. . . . . . . . . . . . . . . . . . . . . . . 15
		- 1.3.2 æ¦‚ç‡çš„åŠ æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . . . 17
		- 1.3.3 æ¦‚ç‡çš„è¿ç»­æ€§. . . . . . . . . . . . . . . . . . . . . . . 18
	- 1.4 æ¡ä»¶æ¦‚ç‡å’Œä¹˜æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . 18
	- 1.5 äº‹ä»¶çš„ç‹¬ç«‹æ€§. . . . . . . . . . . . . . . . . . . . . . . . . . . 21
	- 1.6 å…¨æ¦‚ç‡å…¬å¼ä¸ Bayes å…¬å¼. . . . . . . . . . . . . . . . . . . . 24
		- 1.6.1 å…¨æ¦‚ç‡å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . . 24
		- 1.6.2 Bayes å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . . 28
	- 1.7 æ¦‚ç‡ä¸é¢‘ç‡. . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
- ç¬¬äºŒç«  éšæœºå˜é‡å’Œæ¦‚ç‡åˆ†å¸ƒ
	- 2.1 éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
	- 2.2 ç¦»æ•£å‹éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . 35
	- 2.3 è¿ç»­å‹éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . 43
	- 2.4  æ¦‚ç‡åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . 51
		- 2.4.1 æ¦‚ç‡åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . . . . . 51
		- 2.4.2 å¸¸è§åˆ†å¸ƒçš„åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . 54
	- 2.5 éšæœºå˜é‡å‡½æ•°çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 56
- ç¬¬ä¸‰ç«  éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ
	- 3.1 éšæœºå‘é‡åŠå…¶è”åˆåˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . 63
	- 3.2 ç¦»æ•£å‹éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . 65
	- 3.3 è¿ç»­å‹éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . 68
	- 3.4 éšæœºå‘é‡å‡½æ•°çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 75
	- 3.5 æå¤§æå°å€¼çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . 81
	- 3.6 æ¡ä»¶åˆ†å¸ƒå’Œæ¡ä»¶å¯†åº¦. . . . . . . . . . . . . . . . . . . . . . . 84
- ç¬¬å››ç«  æ•°å­¦æœŸæœ›å’Œæ–¹å·®
	- 4.1 æ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
		- 4.1.1 æ•°å­¦æœŸæœ›æ¦‚å¿µ. . . . . . . . . . . . . . . . . . . . . . . 91
		- 4.1.2 å¸¸è§åˆ†å¸ƒæ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . . . . . 96
	- 4.2 æ•°å­¦æœŸæœ›çš„æ€§è´¨. . . . . . . . . . . . . . . . . . . . . . . . . . 99
		- 4.2.1 éšæœºå‘é‡å‡½æ•°çš„æ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . 99
		- 4.2.2 æ•°å­¦æœŸæœ›çš„æ€§è´¨. . . . . . . . . . . . . . . . . . . . . . 102
	- 4.3 éšæœºå˜é‡çš„æ–¹å·®. . . . . . . . . . . . . . . . . . . . . . . . . . 106
	- 4.4 åæ–¹å·®å’Œç›¸å…³ç³»æ•°. . . . . . . . . . . . . . . . . . . . . . . . 115
- ç¬¬äº”ç«  å¤šå…ƒæ­£æ€åˆ†å¸ƒå’Œæé™å®šç†
	- 5.1 å¤šå…ƒæ­£æ€åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . . . . 119
	- 5.2 å¤§æ•°å¾‹. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
	- 5.3 ä¸­å¿ƒæé™å®šç†. . . . . . . . . . . . . . . . . . . . . . . . . . . 126
- ç¬¬å…­ç«  æè¿°æ€§ç»Ÿè®¡
	- 6.1 æ€»ä½“å’Œå‚æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
	- 6.2 æŠ½æ ·è°ƒæŸ¥æ–¹æ³•. . . . . . . . . . . . . . . . . . . . . . . . . . . 133
	- 6.3 ç”¨æ ·æœ¬ä¼°è®¡æ€»ä½“åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 141
	- 6.4 ä¼—æ•°å’Œä¸­ä½æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . 148
	- 6.5 éšæœºå¯¹ç…§è¯•éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . . 152
- ç¬¬ä¸ƒç«  å‚æ•°ä¼°è®¡
	- 7.1 ç‚¹ä¼°è®¡å’ŒçŸ©ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . . . . 159
	- 7.2 æœ€å¤§ä¼¼ç„¶ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . . . . . 166
		- 7.2.1 ç¦»æ•£å‹éšæœºå˜é‡çš„æƒ…å†µ. . . . . . . . . . . . . . . . . . 166
		- 7.2.2 è¿ç»­å‹éšæœºå˜é‡çš„æƒ…å†µ. . . . . . . . . . . . . . . . . . 168
	- 7.3 æŠ½æ ·åˆ†å¸ƒåŠå…¶ä¸Š Î± åˆ†ä½æ•°. . . . . . . . . . . . . . . . . . . . 173
		- 7.3.1 æŠ½æ ·åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . . 174
		- 7.3.2 æŠ½æ ·åˆ†å¸ƒçš„ä¸Š Î± åˆ†ä½æ•°. . . . . . . . . . . . . . . . . 179
	- 7.4 æ­£æ€æ€»ä½“çš„åŒºé—´ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . 182
		- 7.4.1 å·²çŸ¥ Ïƒ æ—¶, Âµ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . 183
		- 7.4.2 æœªçŸ¥ Ïƒ æ—¶ Âµ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . 185
		- 7.4.3 æ–¹å·® $Ïƒ_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . 187
		- 7.4.4 å‡å€¼å·® $Âµ_1âˆ’Âµ_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . 189
		- 7.4.5 æ–¹å·®æ¯” $Ïƒ^2_1 /Ïƒ^2_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . 191
		- 7.4.6 å•ä¾§ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . . . . 191
	- 7.5 éæ­£æ€æ€»ä½“å’Œæ¯”ä¾‹ p çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . 192
		- 7.5.1 æ­£æ€é€¼è¿‘æ³•. . . . . . . . . . . . . . . . . . . . . . . . 192
		- 7.5.2 æ¯”ä¾‹ p çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . 194
- ç¬¬å…«ç«  å‡è®¾æ£€éªŒ
	- 8.1 å‡è®¾æ£€éªŒçš„æ¦‚å¿µ. . . . . . . . . . . . . . . . . . . . . . . . . . 197
	- 8.2 æ­£æ€å‡å€¼çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 201
		- 8.2.1 å·²çŸ¥ Ïƒ æ—¶, Âµ çš„æ­£æ€æ£€éªŒæ³•. . . . . . . . . . . . . . . 201
		- 8.2.2 p å€¼æ£€éªŒæ³•. . . . . . . . . . . . . . . . . . . . . . . . 203
		- 8.2.3 æœªçŸ¥ Ïƒ æ—¶, å‡å€¼ Âµ çš„ t æ£€éªŒæ³•. . . . . . . . . . . . . . 204
		- 8.2.4 æœªçŸ¥ Ïƒ æ—¶, Âµ çš„å•è¾¹æ£€éªŒæ³•. . . . . . . . . . . . . . . 205
		- 8.2.5 æ­£æ€è¿‘ä¼¼æ³•. . . . . . . . . . . . . . . . . . . . . . . . 208
	- 8.3 æ ·æœ¬é‡çš„é€‰æ‹©. . . . . . . . . . . . . . . . . . . . . . . . . . . 209
	- 8.4 å‡å€¼æ¯”è¾ƒçš„æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 210
		- 8.4.1 å·²çŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$ æ—¶, $Âµ_1 \text{, } Âµ_2$ çš„æ£€éªŒ. . . . . . . . . . . . . . 211
		- 8.4.2 æœªçŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$, ä½†å·²çŸ¥ $Ïƒ^2_1 = Ïƒ^2_2$ æ—¶, $Âµ_1 - Âµ_2$ çš„æ£€éªŒ. . . . 213
		- 8.4.3 æˆå¯¹æ•°æ®çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . 214
		- 8.4.4 æœªçŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$ æ—¶, $Âµ_1 \text{, } Âµ_2$ çš„æ£€éªŒ. . . . . . . . . . . . . . 216
	- 8.5 æ–¹å·®çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 217
	- 8.6 æ¯”ä¾‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 219
		- 8.6.1 å°æ ·æœ¬æƒ…å†µä¸‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . 219
		- 8.6.2 å¤§æ ·æœ¬æƒ…å†µä¸‹å•ä¸ªæ¯”ä¾‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . 221
		- 8.6.3 å¤§æ ·æœ¬æƒ…å†µä¸‹ä¸¤ä¸ªæ€»ä½“æ¯”ä¾‹çš„æ¯”è¾ƒ. . . . . . . . . . . 224
	- 8.7 æ€»ä½“åˆ†å¸ƒçš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 227
- ç¬¬ä¹ç«  çº¿æ€§å›å½’åˆ†æ 233
	- 9.1 æ•°æ®çš„ç›¸å…³æ€§. . . . . . . . . . . . . . . . . . . . . . . . . . . 233
		- 9.1.1 æ ·æœ¬ç›¸å…³ç³»æ•°. . . . . . . . . . . . . . . . . . . . . . . 234
		- 9.1.2 ç›¸å…³æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . 236
	- 9.2 å›å½’ç›´çº¿. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
	- 9.3 ä¸€å…ƒçº¿æ€§å›å½’. . . . . . . . . . . . . . . . . . . . . . . . . . . 242
		- 9.3.1 æœ€å¤§ä¼¼ç„¶ä¼°è®¡å’Œæœ€å°äºŒä¹˜ä¼°è®¡. . . . . . . . . . . . . . 243
		- 9.3.2 å¹³æ–¹å’Œåˆ†è§£å…¬å¼. . . . . . . . . . . . . . . . . . . . . . 247
		- 9.3.3 æ–œç‡ b çš„æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 248
		- 9.3.4 é¢„æµ‹çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . . . 249
	- 9.4 å¤šå…ƒçº¿æ€§å›å½’. . . . . . . . . . . . . . . . . . . . . . . . . . . 251
		- 9.4.1 æœ€å°äºŒä¹˜ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . 252
		- 9.4.2 å›å½’æ˜¾è‘—æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . 253
		- 9.4.3 å•ä¸ªç³»æ•°çš„æ˜¾è‘—æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . 254
		- 9.4.4 æ®‹å·®è¯Šæ–­. . . . . . . . . . . . . . . . . . . . . . . . . 255

ğŸ¬ã€Šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ã€‹æ•™å­¦è§†é¢‘å…¨é›†ï¼ˆå®‹æµ© https://www.bilibili.com/video/BV1ot411y7mU?p=9&share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ğŸ¬ã€æ¯”åˆ·å‰§è¿˜çˆ½!ã€‘ä¸€ç”Ÿæ¨ï¼ï¼ã€éº»çœç†å·¥å…¬å¼€è¯¾ã€‘å¬è¯´ä½ æ¦‚ç‡è®ºæŒ‚äº†ï¼Ÿ MIT æ¦‚ç‡è®º (ä¸­è‹±åŒè¯­å­—å¹•)å®Œæ•´ç‰ˆå…¨25è®²ï¼Œæ¦‚ç‡è®ºåº”è¯¥è¿™æ ·å­¦ https://www.bilibili.com/video/BV1MV4y1W73J?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ğŸ“– æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡, é™ˆå¸Œå­º

ğŸ“– ç»Ÿè®¡å­¦ä¹ æ–¹æ³•, æèˆª

ğŸ“– INTRODUCTION TO PROBABILITY AND STATISTICS FOR ENGINEERS AND SCIENTISTS 
ğŸ“– A FIRST COURSE IN PROBABILITY
ğŸ“– Introduction to Probability Model (PM)
ğŸ“– Stochastic Process (SP)
Sheldon M. Ross

ğŸ“– è´å¶æ–¯åæ¼”

ğŸ“– H. Pishro-Nik, "Introduction to probability, statistics, and random processes", available at [https://www.probabilitycourse.com](https://www.probabilitycourse.com/), Kappa Research LLC, 2014.

ğŸ‘ https://www.math.wm.edu/~leemis/chart/UDR/UDR.html
![](../../../../../Assets/Pics/Screenshot%202025-10-05%20at%2023.37.13.png)

ğŸ‘ https://stanford.edu/~shervine/teaching/cme-106/
CME 106 â€• Introduction to Probability and Statistics for Engineers  
My twin brotherÂ [Afshine](https://twitter.com/afshinea)Â andÂ [I](https://twitter.com/shervinea)Â ([Afshine Amidi](https://twitter.com/afshinea)Â andÂ [Shervine Amidi](https://twitter.com/shervinea)) created this set of cheatsheets when I was a TA for Stanford's CME 106 class in Winter 2018. They can (hopefully!) be useful to all future students taking this course as well as to anyone else interested in learning the fundamentals of Probabilities and Statistics.
- [Probability cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability)
- [Statistics cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics)

ğŸ‘ https://www.wzchen.com/probability-cheatsheet
https://github.com/wzchen/probability_cheatsheet
- This cheatsheet is a 10-page reference in probability that covers a semester's worth of introductory probability.
- The cheatsheet is based off of Harvard's introductory probability course, Stat 110. It is co-authored by former Stat 110 Teaching Fellow William Chen and Stat 110 Professor Joe Blitzstein.



## Intro
### Probability ğŸ†š Statistics?
> ğŸ¤– Gemini 2.5

Probability and statistics are two different, though related, fields that work in opposite directions:Â ==probability uses existing models and rules to predict future events, while statistics uses observed data to infer the underlying rules or models==.Â In essence, probability moves from model to data, and statistics moves from data to model.

> ğŸ”— https://zh.wikipedia.org/zh-hans/Portal:%E6%A6%82%E7%8E%87%E4%B8%8E%E7%BB%9F%E8%AE%A1

æ¦‚ç‡è®ºæ˜¯é›†ä¸­ç ”ç©¶æ¦‚ç‡åŠéšæœºç°è±¡çš„æ•°å­¦åˆ†æ”¯ï¼Œä¸»è¦ç ”ç©¶å¯¹è±¡ä¸ºéšæœºäº‹ä»¶ã€éšæœºå˜é‡ä»¥åŠéšæœºè¿‡ç¨‹ã€‚å¯¹äºéšæœºäº‹ä»¶æ˜¯ä¸å¯èƒ½å‡†ç¡®é¢„æµ‹å…¶ç»“æœçš„ï¼Œç„¶è€Œå¯¹äºä¸€ç³»åˆ—çš„ç‹¬ç«‹éšæœºäº‹ä»¶â€”â€”ä¾‹å¦‚æ·éª°å­ã€æ‰”ç¡¬å¸ã€æŠ½æ‰‘å…‹ç‰Œä»¥åŠè½®ç›˜ç­‰ï¼Œä¼šå‘ˆç°å‡ºä¸€å®šçš„ã€å¯ä»¥è¢«ç”¨äºç ”ç©¶åŠé¢„æµ‹çš„è§„å¾‹ï¼Œä¸¤ä¸ªç”¨æ¥æè¿°è¿™äº›è§„å¾‹çš„æœ€å…·ä»£è¡¨æ€§çš„æ•°å­¦ç»“è®ºåˆ†åˆ«æ˜¯å¤§æ•°å®šå¾‹å’Œä¸­å¿ƒæé™å®šç†ã€‚

ä½œä¸ºç»Ÿè®¡å­¦çš„æ•°å­¦åŸºç¡€ï¼Œæ¦‚ç‡è®ºå¯¹è¯¸å¤šæ¶‰åŠå¤§é‡æ•°æ®å®šé‡åˆ†æçš„äººç±»æ´»åŠ¨æä¸ºé‡è¦ï¼Œæ¦‚ç‡è®ºçš„æ–¹æ³•åŒæ ·é€‚ç”¨äºå…¶ä»–æ–¹é¢ï¼Œä¾‹å¦‚æ˜¯å¯¹åªçŸ¥é“ç³»ç»Ÿéƒ¨åˆ†çŠ¶æ€çš„å¤æ‚ç³»ç»Ÿçš„æè¿°â€”â€”ç»Ÿè®¡åŠ›å­¦ï¼Œè€ŒäºŒåä¸–çºªç‰©ç†å­¦çš„é‡å¤§å‘ç°æ˜¯ä»¥é‡å­åŠ›å­¦æ‰€æè¿°çš„åŸå­å°ºåº¦ä¸Šç‰©ç†ç°è±¡çš„æ¦‚ç‡æœ¬è´¨ã€‚

ç»Ÿè®¡å­¦æ˜¯å¯¹æ•°æ®çš„æ”¶é›†ã€åˆ†æã€è§£é‡Šã€å±•ç¤ºã€æ•´ç†è¿›è¡Œç ”ç©¶çš„å­¦ç§‘ï¼Œå¹¿æ³›åœ°åº”ç”¨åœ¨å„é—¨å­¦ç§‘ï¼Œä»è‡ªç„¶ç§‘å­¦ã€ç¤¾ä¼šç§‘å­¦åˆ°äººæ–‡å­¦ç§‘ï¼Œç”šè‡³è¢«ç”¨æ¥å·¥å•†ä¸šåŠæ”¿åºœçš„æƒ…æŠ¥å†³ç­–ä¹‹ä¸Šã€‚å…¶ä¸­ç”¨æ¥æè¿°ã€æ‘˜è¦æ•°æ®æƒ…å†µçš„ç»Ÿè®¡æ–¹æ³•ç§°ä¸ºæè¿°ç»Ÿè®¡å­¦ï¼›è€Œå¯¹è§‚æµ‹ä¸­éšæœºæ€§å’Œä¸ç¡®å®šæ€§ï¼Œå¯ä»¥é€šè¿‡å¯¹è§‚æµ‹æ•°æ®è¿›è¡Œæ•°å­¦å»ºæ¨¡æ‰€å¾—çš„è§„å¾‹è¿›è¡Œè§£é‡Šï¼Œç„¶ååˆ©ç”¨è¿™äº›è§„å¾‹å¯¹æ‰€ç ”ç©¶çš„è¿‡ç¨‹æˆ–æ€»ä½“è¿›è¡Œæ¨æ–­ï¼Œè¿™æ ·çš„ç»Ÿè®¡æ–¹æ³•ç§°ä¸ºæ¨è®ºç»Ÿè®¡å­¦ã€‚

> ğŸ”— https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/node12.html#

Probability and statistics are related areas of mathematics which concern themselves with analyzing the relative frequency of events. Still, there are fundamental differences in the way they see the world:
- _Probability_Â deals with predicting the likelihood of future events, whileÂ _statistics_Â involves the analysis of the frequency of past events.Â Â Â 
- _Probability_Â is primarily a theoretical branch of mathematics, which studies the consequences of mathematical definitions.Â _Statistics_Â is primarily an applied branch of mathematics, which tries to make sense of observations in the real world.

Both subjects are important, relevant, and useful. But they are different, and understanding the distinction is crucial in properly interpreting the relevance of mathematical evidence. Many a gambler has gone to a cold and lonely grave for failing to make the proper distinction between probability and statistics.

This distinction will perhaps become clearer if we trace the thought process of a mathematician encountering her first craps game:
- If this mathematician were a probabilist, she would see the dice and think ``Six-sided dice? Presumably each face of the dice is equally likely to land face up. NowÂ _assuming_Â that each face comes up with probability 1/6, I can figure out what my chances of crapping out are.''
- If instead a statistician wandered by, she would see the dice and think ``Those dice may look OK, but how do IÂ _know_Â that they are not loaded? I'll watch a while, and keep track of how often each number comes up. Then I can decide if my observations are consistent with the assumption of equal-probability faces. Once I'm confident enough that the dice are fair, I'll call a probabilist to tell me how to play.''

In summary, probability theory enables us to find the consequences of a given ideal world, while statistical theory enables us to to measure the extent to which our world is ideal.

Modern probability theory emerged from the dice tables of France in 1654. Chevalier de MÃ©rÃ©, a French nobleman, wondered whether the player or the house had the advantage in a variation of the following betting game.[6.1](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/footnode.html#foot389)Â In the basic version, the player rolls four dice, and wins provided none of them are a six. The house collects on the even money bet if at least one six appears.Â Â 

De MÃ©rÃ© brought this problem to attention of the French mathematicians Blaise Pascal and Pierre de Fermat, most famous as the source of Fermat's Last Theorem. Together, these men worked out the basics of probability theory, along the way establishing that the house wins the basic version with probabilityÂ ![$p = 1 - (5/6)^4 \approx 0.517$](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/img12.gif), where the probabilityÂ _p_Â = 0.5 would denote a fair game where the house wins exactly half the time.Â Â Â Â The jai-alai world of our Monte Carlo simulation assumes that we decide the outcome of a point between two teams by flipping a suitably biased coin. If this world were reality, our simulation will compute the correct probability of each possible betting outcome. But all players are not created equal, of course. By doing a statistical study of the outcome of all the matches involving a particular player, we can determine an appropriate amount to bias the coin.

But such computations only make sense if our simulated jai-alai world is a model consistent with the real world. John von Neuman once said that ``the valuation of a poker hand can be sheer mathematics.'' We have to reduce our evaluation of a pelotari to sheer mathematics.



## Ref
[ğŸ¤” Zero probability and impossibility | StackExchange, Mathematics]: https://math.stackexchange.com/q/41107/1230830
I Â think the crux of the matter is what probability actuallyÂ _is_:
- **The Bayesian view**Â - probabilities are measures of (personal) confidence or belief, so it's quite obvious why an event with probability zero is not the same thing as an impossible event. But perhaps this isn't such a satisfactory answer.
- **The frequentist view**Â - probabilities are the asymptotic frequency of events as the number of independent trials tends to infinity. Here again wee see that something that happens with probability zero is not the same as something impossible; it's just something that happens so infrequently that the numerator inÂ $\frac{occurences}{trials}$Â is dominated by the denominator.

---
LetÂ ğ´Â be an event,Â PrÂ be the probability measure.

ğ´Â has zero probability ifÂ Pr(ğ´)=0.

ğ´Â is impossible ifÂ ğ´=âˆ….

**Impossibility implies zero probability, but the reverse is false.** Consider the real lineÂ â„; if you randomly select a numberÂ ğ‘¥, the probability thatÂ ğ‘¥=0Â isÂ 0, but this is not impossible. In fact, the probability thatÂ ğ‘¥Â belongs to some countable set, e.gÂ â„š, is alsoÂ 0.

From a purely mathematical point of view, impossibility is simply a stronger statement, so impossibilityÂ _cannot_Â be described by probability measure. However, another way of thinking might shed some light. That is, if the probability that something exists has probability greater thanÂ 0, then it exists. This notion has been used for some mathematical arguments.

---
Zero probability isn't impossibility. If you were to choose a random number from the real line, 1 has zero probability of being chosen, but still it's possible to choose 1.

---
Mathematicians generally formalize probability using the notion of aÂ [probability space](http://en.wikipedia.org/wiki/Probability_space)Â and measure theory. In this formalism it is possible for an event to have probabilityÂ 0Â without being the empty event. Perhaps the simplest "realistic" (and I use the word loosely) example of such an event is the event of flipping only heads infinitely many times. This event has probabilityÂ 0, but it is not empty, which is what one might call a formal definition of "impossible."

The underlying probability space is the set of possible ways to flip a coin infinitely many times. An example of an impossible event here is that you flip, say, cat. The coin has only a heads side and a tails side; it doesn't have a cat side, so flipping cat is impossible.

(Whether this formalism says anything reasonable about the real world is debatable. In practice, events of sufficiently small probability are already impossible. The above is just a statement about a certain mathematical formalism that has proven to be useful in certain contexts. In mathematics, we want to prove statements about some class of objects. Sometimes we can prove that the statement holds with probabilityÂ 1, but this does not imply that it holds for all objects, and since we actually care aboutÂ _all_Â objects this distinction really does need to be made in mathematics.)
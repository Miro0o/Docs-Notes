# Probabilities  & Statistics

[TOC]



## Res
### Related Topics
â†— [Statistical Learning Theory](../../../ğŸ§ %20Computing%20Methodologies/ğŸ‘½%20Artificial%20Intelligence/ğŸ—ï¸%20AI%20Basics%20&%20Machine%20Learning/ğŸ“Œ%20Statistical%20Learning%20Theory/Statistical%20Learning%20Theory.md)
â†— [Data-Oriented & Human-Centered Technologies](../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data-Oriented%20&%20Human-Centered%20Technologies.md)
- â†— [Data Mining](../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data%20Science/â›ï¸%20Data%20Mining/Data%20Mining.md)

â†— [Statistical Learning Theory](../../../ğŸ§ %20Computing%20Methodologies/ğŸ‘½%20Artificial%20Intelligence/ğŸ—ï¸%20AI%20Basics%20&%20Machine%20Learning/ğŸ“Œ%20Statistical%20Learning%20Theory/Statistical%20Learning%20Theory.md)


### Learning Resources
ğŸ« [UBC CS70 : discrete Math and probability theory](../ğŸ  Assets/UC Berkeley/CS70 : Discrete Math and Probability Theory/Intro.md) 
ğŸ« [UBC CS126 : Probability Theory](../ğŸ  Assets/UC Berkeley/CS126 : Probability Theory/Intro.md) 


ğŸ¬ã€Šæ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡ã€‹æ•™å­¦è§†é¢‘å…¨é›†ï¼ˆå®‹æµ© https://www.bilibili.com/video/BV1ot411y7mU?p=9&share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ğŸ¬ã€æ¯”åˆ·å‰§è¿˜çˆ½!ã€‘ä¸€ç”Ÿæ¨ï¼ï¼ã€éº»çœç†å·¥å…¬å¼€è¯¾ã€‘å¬è¯´ä½ æ¦‚ç‡è®ºæŒ‚äº†ï¼Ÿ MIT æ¦‚ç‡è®º (ä¸­è‹±åŒè¯­å­—å¹•)å®Œæ•´ç‰ˆå…¨25è®²ï¼Œæ¦‚ç‡è®ºåº”è¯¥è¿™æ ·å­¦ https://www.bilibili.com/video/BV1MV4y1W73J?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ğŸ“– æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡, é™ˆå¸Œå­º

ğŸ“– ç»Ÿè®¡å­¦ä¹ æ–¹æ³•, æèˆª

ğŸ“– INTRODUCTION TO PROBABILITY AND STATISTICS FOR ENGINEERS AND SCIENTISTS 
ğŸ“– A FIRST COURSE IN PROBABILITY
ğŸ“– Introduction to Probability Model (PM)
ğŸ“– Stochastic Process (SP)
Sheldon M. Ross

ğŸ“– è´å¶æ–¯åæ¼”

ğŸ“– H. Pishro-Nik, "Introduction to probability, statistics, and random processes", available at [https://www.probabilitycourse.com](https://www.probabilitycourse.com/), Kappa Research LLC, 2014.



## Intro
### Probability ğŸ†š Statistics?
> ğŸ¤– Gemini 2.5

Probability and statistics are two different, though related, fields that work in opposite directions:Â ==probability uses existing models and rules to predict future events, while statistics uses observed data to infer the underlying rules or models==.Â In essence, probability moves from model to data, and statistics moves from data to model.

> ğŸ”— https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/node12.html#

Probability and statistics are related areas of mathematics which concern themselves with analyzing the relative frequency of events. Still, there are fundamental differences in the way they see the world:
- _Probability_Â deals with predicting the likelihood of future events, whileÂ _statistics_Â involves the analysis of the frequency of past events.Â Â Â 
- _Probability_Â is primarily a theoretical branch of mathematics, which studies the consequences of mathematical definitions.Â _Statistics_Â is primarily an applied branch of mathematics, which tries to make sense of observations in the real world.

Both subjects are important, relevant, and useful. But they are different, and understanding the distinction is crucial in properly interpreting the relevance of mathematical evidence. Many a gambler has gone to a cold and lonely grave for failing to make the proper distinction between probability and statistics.

This distinction will perhaps become clearer if we trace the thought process of a mathematician encountering her first craps game:
- If this mathematician were a probabilist, she would see the dice and think ``Six-sided dice? Presumably each face of the dice is equally likely to land face up. NowÂ _assuming_Â that each face comes up with probability 1/6, I can figure out what my chances of crapping out are.''
- If instead a statistician wandered by, she would see the dice and think ``Those dice may look OK, but how do IÂ _know_Â that they are not loaded? I'll watch a while, and keep track of how often each number comes up. Then I can decide if my observations are consistent with the assumption of equal-probability faces. Once I'm confident enough that the dice are fair, I'll call a probabilist to tell me how to play.''

In summary, probability theory enables us to find the consequences of a given ideal world, while statistical theory enables us to to measure the extent to which our world is ideal.

Modern probability theory emerged from the dice tables of France in 1654. Chevalier de MÃ©rÃ©, a French nobleman, wondered whether the player or the house had the advantage in a variation of the following betting game.[6.1](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/footnode.html#foot389)Â In the basic version, the player rolls four dice, and wins provided none of them are a six. The house collects on the even money bet if at least one six appears.Â Â 

De MÃ©rÃ© brought this problem to attention of the French mathematicians Blaise Pascal and Pierre de Fermat, most famous as the source of Fermat's Last Theorem. Together, these men worked out the basics of probability theory, along the way establishing that the house wins the basic version with probabilityÂ ![$p = 1 - (5/6)^4 \approx 0.517$](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/img12.gif), where the probabilityÂ _p_Â = 0.5 would denote a fair game where the house wins exactly half the time.Â Â Â Â The jai-alai world of our Monte Carlo simulation assumes that we decide the outcome of a point between two teams by flipping a suitably biased coin. If this world were reality, our simulation will compute the correct probability of each possible betting outcome. But all players are not created equal, of course. By doing a statistical study of the outcome of all the matches involving a particular player, we can determine an appropriate amount to bias the coin.

But such computations only make sense if our simulated jai-alai world is a model consistent with the real world. John von Neuman once said that ``the valuation of a poker hand can be sheer mathematics.'' We have to reduce our evaluation of a pelotari to sheer mathematics.



## Ref
[è¯·é—®ä¸‹ Ross çš„éšæœºè¿‡ç¨‹é‚£ä¸ªç‰ˆæœ¬æ¯”è¾ƒå¥½ï¼Ÿ - Mercurialçš„å›ç­” - çŸ¥ä¹]: https://www.zhihu.com/question/389395273/answer/1194198617
è¿™å­¦æœŸå°±åœ¨ä¸ŠSheldonçš„Foundation of Stochastic Processã€‚Rossçš„è¯´æ³•æ˜¯Stochastic Process (ä»¥ä¸‹ç®€ç§°SP)æ˜¯ä¸»è¦æ•™æï¼ŒProbability Model (PM)ä½œä¸ºè¡¥å……ã€‚ä½†å®é™…æƒ…å†µæ˜¯RossåŸºæœ¬æ˜¯ä¸¥æ ¼æŒ‰ç…§PMè®²çš„ï¼ŒSPä¸»è¦ç”¨æ¥å¸ƒç½®ä½œä¸šã€‚å”¯ä¸€çš„ä¾‹å¤–æ˜¯Renewal theoryè¿™ä¸€å—ç”¨SPè®²ã€‚è€ŒRossæ•™çš„æœ¬ç§‘æˆ–master levelçš„éšæœºè¿‡ç¨‹åˆ™æ˜¯åªç”¨PMã€‚æˆ‘çš„å»ºè®®æ˜¯ï¼Œå¦‚æœä½ æ˜¯å·¥ç§‘éæ¦‚ç‡æ–¹å‘çš„ç ”ç©¶ç”Ÿï¼ŒPMå¤Ÿç”¨ã€‚å¦‚æœæ˜¯åšéšæœºè¿‡ç¨‹çš„PhDï¼Œå¯ä»¥ä¸¤æœ¬ä¸€èµ·è¯»ã€‚å¦‚æœä½ æ˜¯æ•°å­¦ç³»åšæ¦‚ç‡çš„PhDï¼Œçœ‹Durrettå§ã€‚

åº”ç”¨éšæœºè¿‡ç¨‹ï¼šæ¦‚ç‡æ¨¡å‹å¯¼è®ºé‚£æœ¬ä¹¦ä¾‹å­ä¸°å¯Œï¼Œå†…å®¹ä¹Ÿå¤šï¼ŒçŸ¥è¯†ç‚¹çš„æ’ç‰ˆæ›´ç³»ç»Ÿä¸€äº›ï¼Œä¸€å…±å¥½åƒæœ‰12ä¸ªç« èŠ‚ï¼Œæ€»ä¹‹ï¼Œå¯ä»¥çœ‹çœ‹ï¼Œï¼ˆå¦‚æœå¯ä»¥ï¼Œå°½é‡çœ‹è‹±æ–‡åŸç‰ˆï¼Œä¸ªäººæ„Ÿè§‰ä¸­æ–‡ç¿»è¯‘çš„ç‰ˆæœ¬åº”è¯¥ä¸å·®ï¼Œä½†æ˜¯è¯»èµ·æ¥æœ‰äº›åˆ«æ‰­ã€‚ï¼‰å¦å¤–ä¸€æœ¬éšæœºè¿‡ç¨‹å†…å®¹ä¸Šæ¥è¯´æ¯”å‰è€…ä¼šå°‘ä¸€äº›ï¼Œä½†æ˜¯è¯¥æœ‰çš„éƒ½è¿˜æ˜¯æœ‰äº†ï¼Œå…·ä½“å°‘çš„å†…å®¹å°±æ˜¯ä¸Šä¸€æœ¬ä¹¦æœ€åä¸€ä¸¤ç« çš„å†…å®¹ï¼Œå¹¶ä¸”å…³äºæ¦‚ç‡çš„ä»‹ç»éƒ½èåˆåœ¨ç¬¬ä¸€ç« äº†ï¼Œè›®å¯ä»¥ã€‚ä¸¤æœ¬éƒ½æŒºå¥½çš„ï¼Œä¸è¿‡çœ‹ä½ é€‚åˆå“ªæœ¬ï¼Œæ¯ä¸ªäººå¯¹ä¹¦çš„å£å‘³ä¸åŒï¼Œæ¯”å¦‚è¯´æˆ‘å°±è§‰å¾—æ¦‚ç‡æ¨¡å‹å¯¼è®ºæ¯”è¾ƒå•°å—¦ï¼Œæˆ‘ä¸€èˆ¬éƒ½æ˜¯å½“å½“â€œå­—å…¸â€ç”¨ã€‚æœ€åï¼Œå­¦ä¹ çš„è¯ï¼Œæœ€å¥½æŠŠè¯¾åä¹ é¢˜éƒ½åšä¸ª60ï¼…+ï¼Œè¿™æ ·æ‰ä¼šçŸ¥é“çŸ¥è¯†ç‚¹å¦‚ä½•å»è¿ç”¨ï¼Œå¯¹å­¦ä¹ è¿™é—¨è¯¾ç¨‹æ˜¯æœ‰è«å¤§çš„å¥½å¤„çš„ï¼
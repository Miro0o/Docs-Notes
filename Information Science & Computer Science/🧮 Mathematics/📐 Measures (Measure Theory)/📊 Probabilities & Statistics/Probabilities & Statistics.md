# Probabilities  & Statistics

[TOC]



## Res
### Related Topics
â†— [Statistical Learning Theory & ML Types](../../../ðŸ§ %20Computing%20Methodologies/ðŸ‘½%20Artificial%20Intelligence/ðŸ—ï¸%20AI%20Basics%20&%20Machine%20Learning%20(ML)/ðŸ“Š%20Statistical%20Learning%20Theory%20&%20ML%20Types/Statistical%20Learning%20Theory%20&%20ML%20Types.md)
â†— [Data-Oriented & Human-Centered Technologies](../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data-Oriented%20&%20Human-Centered%20Technologies.md)
- â†— [Data Science](../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data%20Science/Data%20Science.md)
- â†— [Data Mining](../../../Data-Oriented%20&%20Human-Centered%20Technologies/Data%20Science/â›ï¸%20Data%20Mining/Data%20Mining.md)


### Learning Resources
ðŸ« [UCB /CS70 Discrete Math and Probability Theory](../../../ðŸ—º%20CS%20Overview/ðŸ’‹%20Intro%20to%20Computer%20Science/ðŸ‘©ðŸ¼â€ðŸ«%20Courses%20of%20Universities/UC%20Berkeley/CS70%20Discrete%20Math%20and%20Probability%20Theory/CS70%20Discrete%20Math%20and%20Probability%20Theory.md)
ðŸ« [UCB /CS126 Probability Theory](../../../ðŸ—º%20CS%20Overview/ðŸ’‹%20Intro%20to%20Computer%20Science/ðŸ‘©ðŸ¼â€ðŸ«%20Courses%20of%20Universities/UC%20Berkeley/CS126%20Probability%20Theory/CS126%20Probability%20Theory.md)

ðŸ“– ä½•ä¹¦å…ƒã€Šæ¦‚çŽ‡è®ºä¸Žæ•°ç†ç»Ÿè®¡ã€‹
- ç¬¬ä¸€ç«  å¤å…¸æ¦‚åž‹å’Œæ¦‚çŽ‡ç©ºé—´
	- 1.1 è¯•éªŒä¸Žäº‹ä»¶. . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
	- 1.2 å¤å…¸æ¦‚åž‹ä¸Žå‡ ä½•æ¦‚åž‹. . . . . . . . . . . . . . . . . . . . . . . 7
		- 1.2.1 å¤å…¸æ¦‚åž‹. . . . . . . . . . . . . . . . . . . . . . . . . 7
		- 1.2.2 å‡ ä½•æ¦‚åž‹. . . . . . . . . . . . . . . . . . . . . . . . . 14
	- 1.3 æ¦‚çŽ‡çš„å…¬ç†åŒ–å’ŒåŠ æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . 15
		- 1.3.1 æ¦‚çŽ‡çš„å…¬ç†åŒ–. . . . . . . . . . . . . . . . . . . . . . . 15
		- 1.3.2 æ¦‚çŽ‡çš„åŠ æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . . . 17
		- 1.3.3 æ¦‚çŽ‡çš„è¿žç»­æ€§. . . . . . . . . . . . . . . . . . . . . . . 18
	- 1.4 æ¡ä»¶æ¦‚çŽ‡å’Œä¹˜æ³•å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . 18
	- 1.5 äº‹ä»¶çš„ç‹¬ç«‹æ€§. . . . . . . . . . . . . . . . . . . . . . . . . . . 21
	- 1.6 å…¨æ¦‚çŽ‡å…¬å¼ä¸Ž Bayes å…¬å¼. . . . . . . . . . . . . . . . . . . . 24
		- 1.6.1 å…¨æ¦‚çŽ‡å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . . 24
		- 1.6.2 Bayes å…¬å¼. . . . . . . . . . . . . . . . . . . . . . . . 28
	- 1.7 æ¦‚çŽ‡ä¸Žé¢‘çŽ‡. . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
- ç¬¬äºŒç«  éšæœºå˜é‡å’Œæ¦‚çŽ‡åˆ†å¸ƒ
	- 2.1 éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
	- 2.2 ç¦»æ•£åž‹éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . 35
	- 2.3 è¿žç»­åž‹éšæœºå˜é‡. . . . . . . . . . . . . . . . . . . . . . . . . . 43
	- 2.4  æ¦‚çŽ‡åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . 51
		- 2.4.1 æ¦‚çŽ‡åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . . . . . 51
		- 2.4.2 å¸¸è§åˆ†å¸ƒçš„åˆ†å¸ƒå‡½æ•°. . . . . . . . . . . . . . . . . . . 54
	- 2.5 éšæœºå˜é‡å‡½æ•°çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 56
- ç¬¬ä¸‰ç«  éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ
	- 3.1 éšæœºå‘é‡åŠå…¶è”åˆåˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . 63
	- 3.2 ç¦»æ•£åž‹éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . 65
	- 3.3 è¿žç»­åž‹éšæœºå‘é‡åŠå…¶åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . 68
	- 3.4 éšæœºå‘é‡å‡½æ•°çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 75
	- 3.5 æžå¤§æžå°å€¼çš„åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . 81
	- 3.6 æ¡ä»¶åˆ†å¸ƒå’Œæ¡ä»¶å¯†åº¦. . . . . . . . . . . . . . . . . . . . . . . 84
- ç¬¬å››ç«  æ•°å­¦æœŸæœ›å’Œæ–¹å·®
	- 4.1 æ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
		- 4.1.1 æ•°å­¦æœŸæœ›æ¦‚å¿µ. . . . . . . . . . . . . . . . . . . . . . . 91
		- 4.1.2 å¸¸è§åˆ†å¸ƒæ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . . . . . 96
	- 4.2 æ•°å­¦æœŸæœ›çš„æ€§è´¨. . . . . . . . . . . . . . . . . . . . . . . . . . 99
		- 4.2.1 éšæœºå‘é‡å‡½æ•°çš„æ•°å­¦æœŸæœ›. . . . . . . . . . . . . . . . 99
		- 4.2.2 æ•°å­¦æœŸæœ›çš„æ€§è´¨. . . . . . . . . . . . . . . . . . . . . . 102
	- 4.3 éšæœºå˜é‡çš„æ–¹å·®. . . . . . . . . . . . . . . . . . . . . . . . . . 106
	- 4.4 åæ–¹å·®å’Œç›¸å…³ç³»æ•°. . . . . . . . . . . . . . . . . . . . . . . . 115
- ç¬¬äº”ç«  å¤šå…ƒæ­£æ€åˆ†å¸ƒå’Œæžé™å®šç†
	- 5.1 å¤šå…ƒæ­£æ€åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . . . . 119
	- 5.2 å¤§æ•°å¾‹. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
	- 5.3 ä¸­å¿ƒæžé™å®šç†. . . . . . . . . . . . . . . . . . . . . . . . . . . 126
- ç¬¬å…­ç«  æè¿°æ€§ç»Ÿè®¡
	- 6.1 æ€»ä½“å’Œå‚æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
	- 6.2 æŠ½æ ·è°ƒæŸ¥æ–¹æ³•. . . . . . . . . . . . . . . . . . . . . . . . . . . 133
	- 6.3 ç”¨æ ·æœ¬ä¼°è®¡æ€»ä½“åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . 141
	- 6.4 ä¼—æ•°å’Œä¸­ä½æ•°. . . . . . . . . . . . . . . . . . . . . . . . . . . 148
	- 6.5 éšæœºå¯¹ç…§è¯•éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . . 152
- ç¬¬ä¸ƒç«  å‚æ•°ä¼°è®¡
	- 7.1 ç‚¹ä¼°è®¡å’ŒçŸ©ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . . . . 159
	- 7.2 æœ€å¤§ä¼¼ç„¶ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . . . . . 166
		- 7.2.1 ç¦»æ•£åž‹éšæœºå˜é‡çš„æƒ…å†µ. . . . . . . . . . . . . . . . . . 166
		- 7.2.2 è¿žç»­åž‹éšæœºå˜é‡çš„æƒ…å†µ. . . . . . . . . . . . . . . . . . 168
	- 7.3 æŠ½æ ·åˆ†å¸ƒåŠå…¶ä¸Š Î± åˆ†ä½æ•°. . . . . . . . . . . . . . . . . . . . 173
		- 7.3.1 æŠ½æ ·åˆ†å¸ƒ. . . . . . . . . . . . . . . . . . . . . . . . . 174
		- 7.3.2 æŠ½æ ·åˆ†å¸ƒçš„ä¸Š Î± åˆ†ä½æ•°. . . . . . . . . . . . . . . . . 179
	- 7.4 æ­£æ€æ€»ä½“çš„åŒºé—´ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . 182
		- 7.4.1 å·²çŸ¥ Ïƒ æ—¶, Âµ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . 183
		- 7.4.2 æœªçŸ¥ Ïƒ æ—¶ Âµ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . 185
		- 7.4.3 æ–¹å·® $Ïƒ_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . 187
		- 7.4.4 å‡å€¼å·® $Âµ_1âˆ’Âµ_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . 189
		- 7.4.5 æ–¹å·®æ¯” $Ïƒ^2_1 /Ïƒ^2_2$ çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . 191
		- 7.4.6 å•ä¾§ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . . . . 191
	- 7.5 éžæ­£æ€æ€»ä½“å’Œæ¯”ä¾‹ p çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . 192
		- 7.5.1 æ­£æ€é€¼è¿‘æ³•. . . . . . . . . . . . . . . . . . . . . . . . 192
		- 7.5.2 æ¯”ä¾‹ p çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . 194
- ç¬¬å…«ç«  å‡è®¾æ£€éªŒ
	- 8.1 å‡è®¾æ£€éªŒçš„æ¦‚å¿µ. . . . . . . . . . . . . . . . . . . . . . . . . . 197
	- 8.2 æ­£æ€å‡å€¼çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 201
		- 8.2.1 å·²çŸ¥ Ïƒ æ—¶, Âµ çš„æ­£æ€æ£€éªŒæ³•. . . . . . . . . . . . . . . 201
		- 8.2.2 p å€¼æ£€éªŒæ³•. . . . . . . . . . . . . . . . . . . . . . . . 203
		- 8.2.3 æœªçŸ¥ Ïƒ æ—¶, å‡å€¼ Âµ çš„ t æ£€éªŒæ³•. . . . . . . . . . . . . . 204
		- 8.2.4 æœªçŸ¥ Ïƒ æ—¶, Âµ çš„å•è¾¹æ£€éªŒæ³•. . . . . . . . . . . . . . . 205
		- 8.2.5 æ­£æ€è¿‘ä¼¼æ³•. . . . . . . . . . . . . . . . . . . . . . . . 208
	- 8.3 æ ·æœ¬é‡çš„é€‰æ‹©. . . . . . . . . . . . . . . . . . . . . . . . . . . 209
	- 8.4 å‡å€¼æ¯”è¾ƒçš„æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 210
		- 8.4.1 å·²çŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$ æ—¶, $Âµ_1 \text{, } Âµ_2$ çš„æ£€éªŒ. . . . . . . . . . . . . . 211
		- 8.4.2 æœªçŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$, ä½†å·²çŸ¥ $Ïƒ^2_1 = Ïƒ^2_2$ æ—¶, $Âµ_1 - Âµ_2$ çš„æ£€éªŒ. . . . 213
		- 8.4.3 æˆå¯¹æ•°æ®çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . 214
		- 8.4.4 æœªçŸ¥ $Ïƒ^2_1 \text{, } Ïƒ^2_2$ æ—¶, $Âµ_1 \text{, } Âµ_2$ çš„æ£€éªŒ. . . . . . . . . . . . . . 216
	- 8.5 æ–¹å·®çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 217
	- 8.6 æ¯”ä¾‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . . . 219
		- 8.6.1 å°æ ·æœ¬æƒ…å†µä¸‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . 219
		- 8.6.2 å¤§æ ·æœ¬æƒ…å†µä¸‹å•ä¸ªæ¯”ä¾‹çš„å‡è®¾æ£€éªŒ. . . . . . . . . . . 221
		- 8.6.3 å¤§æ ·æœ¬æƒ…å†µä¸‹ä¸¤ä¸ªæ€»ä½“æ¯”ä¾‹çš„æ¯”è¾ƒ. . . . . . . . . . . 224
	- 8.7 æ€»ä½“åˆ†å¸ƒçš„å‡è®¾æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 227
- ç¬¬ä¹ç«  çº¿æ€§å›žå½’åˆ†æž 233
	- 9.1 æ•°æ®çš„ç›¸å…³æ€§. . . . . . . . . . . . . . . . . . . . . . . . . . . 233
		- 9.1.1 æ ·æœ¬ç›¸å…³ç³»æ•°. . . . . . . . . . . . . . . . . . . . . . . 234
		- 9.1.2 ç›¸å…³æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . . 236
	- 9.2 å›žå½’ç›´çº¿. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
	- 9.3 ä¸€å…ƒçº¿æ€§å›žå½’. . . . . . . . . . . . . . . . . . . . . . . . . . . 242
		- 9.3.1 æœ€å¤§ä¼¼ç„¶ä¼°è®¡å’Œæœ€å°äºŒä¹˜ä¼°è®¡. . . . . . . . . . . . . . 243
		- 9.3.2 å¹³æ–¹å’Œåˆ†è§£å…¬å¼. . . . . . . . . . . . . . . . . . . . . . 247
		- 9.3.3 æ–œçŽ‡ b çš„æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . . 248
		- 9.3.4 é¢„æµ‹çš„ç½®ä¿¡åŒºé—´. . . . . . . . . . . . . . . . . . . . . . 249
	- 9.4 å¤šå…ƒçº¿æ€§å›žå½’. . . . . . . . . . . . . . . . . . . . . . . . . . . 251
		- 9.4.1 æœ€å°äºŒä¹˜ä¼°è®¡. . . . . . . . . . . . . . . . . . . . . . . 252
		- 9.4.2 å›žå½’æ˜¾è‘—æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . . . . . 253
		- 9.4.3 å•ä¸ªç³»æ•°çš„æ˜¾è‘—æ€§æ£€éªŒ. . . . . . . . . . . . . . . . . . 254
		- 9.4.4 æ®‹å·®è¯Šæ–­. . . . . . . . . . . . . . . . . . . . . . . . . 255

ðŸŽ¬ã€Šæ¦‚çŽ‡è®ºä¸Žæ•°ç†ç»Ÿè®¡ã€‹æ•™å­¦è§†é¢‘å…¨é›†ï¼ˆå®‹æµ© https://www.bilibili.com/video/BV1ot411y7mU?p=9&share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ðŸŽ¬ã€æ¯”åˆ·å‰§è¿˜çˆ½!ã€‘ä¸€ç”ŸæŽ¨ï¼ï¼ã€éº»çœç†å·¥å…¬å¼€è¯¾ã€‘å¬è¯´ä½ æ¦‚çŽ‡è®ºæŒ‚äº†ï¼Ÿ MIT æ¦‚çŽ‡è®º (ä¸­è‹±åŒè¯­å­—å¹•)å®Œæ•´ç‰ˆå…¨25è®²ï¼Œæ¦‚çŽ‡è®ºåº”è¯¥è¿™æ ·å­¦ https://www.bilibili.com/video/BV1MV4y1W73J?share_source=copy_web&vd_source=7740584ebdab35221363fc24d1582d9d

ðŸ“– æ¦‚çŽ‡è®ºä¸Žæ•°ç†ç»Ÿè®¡, é™ˆå¸Œå­º

ðŸ“– ç»Ÿè®¡å­¦ä¹ æ–¹æ³•, æŽèˆª

ðŸ“– INTRODUCTION TO PROBABILITY AND STATISTICS FOR ENGINEERS AND SCIENTISTS 
ðŸ“– A FIRST COURSE IN PROBABILITY
ðŸ“– Introduction to Probability Model (PM)
ðŸ“– Stochastic Process (SP)
Sheldon M. Ross

ðŸ“– è´å¶æ–¯åæ¼”

ðŸ“– H. Pishro-Nik, "Introduction to probability, statistics, and random processes", available at [https://www.probabilitycourse.com](https://www.probabilitycourse.com/), Kappa Research LLC, 2014.

ðŸ‘ https://www.math.wm.edu/~leemis/chart/UDR/UDR.html
![](../../../../Assets/Pics/Screenshot%202025-10-05%20at%2023.37.13.png)

ðŸ‘ https://stanford.edu/~shervine/teaching/cme-106/
CME 106 â€• Introduction to Probability and Statistics for Engineers  
My twin brotherÂ [Afshine](https://twitter.com/afshinea)Â andÂ [I](https://twitter.com/shervinea)Â ([Afshine Amidi](https://twitter.com/afshinea)Â andÂ [Shervine Amidi](https://twitter.com/shervinea)) created this set of cheatsheets when I was a TA for Stanford's CME 106 class in Winter 2018. They can (hopefully!) be useful to all future students taking this course as well as to anyone else interested in learning the fundamentals of Probabilities and Statistics.
- [Probability cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-probability)
- [Statistics cheatsheet](https://stanford.edu/~shervine/teaching/cme-106/cheatsheet-statistics)

ðŸ‘ https://www.wzchen.com/probability-cheatsheet
https://github.com/wzchen/probability_cheatsheet
- This cheatsheet is a 10-page reference in probability that covers a semester's worth of introductory probability.
- The cheatsheet is based off of Harvard's introductory probability course, Stat 110. It is co-authored by former Stat 110 Teaching Fellow William Chen and Stat 110 Professor Joe Blitzstein.



## Intro
### Probability ðŸ†š Statistics?
> ðŸ¤– Gemini 2.5

Probability and statistics are two different, though related, fields that work in opposite directions:Â ==probability uses existing models and rules to predict future events, while statistics uses observed data to infer the underlying rules or models==.Â In essence, probability moves from model to data, and statistics moves from data to model.

> ðŸ”— https://zh.wikipedia.org/zh-hans/Portal:%E6%A6%82%E7%8E%87%E4%B8%8E%E7%BB%9F%E8%AE%A1

æ¦‚çŽ‡è®ºæ˜¯é›†ä¸­ç ”ç©¶æ¦‚çŽ‡åŠéšæœºçŽ°è±¡çš„æ•°å­¦åˆ†æ”¯ï¼Œä¸»è¦ç ”ç©¶å¯¹è±¡ä¸ºéšæœºäº‹ä»¶ã€éšæœºå˜é‡ä»¥åŠéšæœºè¿‡ç¨‹ã€‚å¯¹äºŽéšæœºäº‹ä»¶æ˜¯ä¸å¯èƒ½å‡†ç¡®é¢„æµ‹å…¶ç»“æžœçš„ï¼Œç„¶è€Œå¯¹äºŽä¸€ç³»åˆ—çš„ç‹¬ç«‹éšæœºäº‹ä»¶â€”â€”ä¾‹å¦‚æŽ·éª°å­ã€æ‰”ç¡¬å¸ã€æŠ½æ‰‘å…‹ç‰Œä»¥åŠè½®ç›˜ç­‰ï¼Œä¼šå‘ˆçŽ°å‡ºä¸€å®šçš„ã€å¯ä»¥è¢«ç”¨äºŽç ”ç©¶åŠé¢„æµ‹çš„è§„å¾‹ï¼Œä¸¤ä¸ªç”¨æ¥æè¿°è¿™äº›è§„å¾‹çš„æœ€å…·ä»£è¡¨æ€§çš„æ•°å­¦ç»“è®ºåˆ†åˆ«æ˜¯å¤§æ•°å®šå¾‹å’Œä¸­å¿ƒæžé™å®šç†ã€‚

ä½œä¸ºç»Ÿè®¡å­¦çš„æ•°å­¦åŸºç¡€ï¼Œæ¦‚çŽ‡è®ºå¯¹è¯¸å¤šæ¶‰åŠå¤§é‡æ•°æ®å®šé‡åˆ†æžçš„äººç±»æ´»åŠ¨æžä¸ºé‡è¦ï¼Œæ¦‚çŽ‡è®ºçš„æ–¹æ³•åŒæ ·é€‚ç”¨äºŽå…¶ä»–æ–¹é¢ï¼Œä¾‹å¦‚æ˜¯å¯¹åªçŸ¥é“ç³»ç»Ÿéƒ¨åˆ†çŠ¶æ€çš„å¤æ‚ç³»ç»Ÿçš„æè¿°â€”â€”ç»Ÿè®¡åŠ›å­¦ï¼Œè€ŒäºŒåä¸–çºªç‰©ç†å­¦çš„é‡å¤§å‘çŽ°æ˜¯ä»¥é‡å­åŠ›å­¦æ‰€æè¿°çš„åŽŸå­å°ºåº¦ä¸Šç‰©ç†çŽ°è±¡çš„æ¦‚çŽ‡æœ¬è´¨ã€‚

ç»Ÿè®¡å­¦æ˜¯å¯¹æ•°æ®çš„æ”¶é›†ã€åˆ†æžã€è§£é‡Šã€å±•ç¤ºã€æ•´ç†è¿›è¡Œç ”ç©¶çš„å­¦ç§‘ï¼Œå¹¿æ³›åœ°åº”ç”¨åœ¨å„é—¨å­¦ç§‘ï¼Œä»Žè‡ªç„¶ç§‘å­¦ã€ç¤¾ä¼šç§‘å­¦åˆ°äººæ–‡å­¦ç§‘ï¼Œç”šè‡³è¢«ç”¨æ¥å·¥å•†ä¸šåŠæ”¿åºœçš„æƒ…æŠ¥å†³ç­–ä¹‹ä¸Šã€‚å…¶ä¸­ç”¨æ¥æè¿°ã€æ‘˜è¦æ•°æ®æƒ…å†µçš„ç»Ÿè®¡æ–¹æ³•ç§°ä¸ºæè¿°ç»Ÿè®¡å­¦ï¼›è€Œå¯¹è§‚æµ‹ä¸­éšæœºæ€§å’Œä¸ç¡®å®šæ€§ï¼Œå¯ä»¥é€šè¿‡å¯¹è§‚æµ‹æ•°æ®è¿›è¡Œæ•°å­¦å»ºæ¨¡æ‰€å¾—çš„è§„å¾‹è¿›è¡Œè§£é‡Šï¼Œç„¶åŽåˆ©ç”¨è¿™äº›è§„å¾‹å¯¹æ‰€ç ”ç©¶çš„è¿‡ç¨‹æˆ–æ€»ä½“è¿›è¡ŒæŽ¨æ–­ï¼Œè¿™æ ·çš„ç»Ÿè®¡æ–¹æ³•ç§°ä¸ºæŽ¨è®ºç»Ÿè®¡å­¦ã€‚

> ðŸ”— https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/node12.html#

Probability and statistics are related areas of mathematics which concern themselves with analyzing the relative frequency of events. Still, there are fundamental differences in the way they see the world:
- _Probability_Â deals with predicting the likelihood of future events, whileÂ _statistics_Â involves the analysis of the frequency of past events.Â Â Â 
- _Probability_Â is primarily a theoretical branch of mathematics, which studies the consequences of mathematical definitions.Â _Statistics_Â is primarily an applied branch of mathematics, which tries to make sense of observations in the real world.

Both subjects are important, relevant, and useful. But they are different, and understanding the distinction is crucial in properly interpreting the relevance of mathematical evidence. Many a gambler has gone to a cold and lonely grave for failing to make the proper distinction between probability and statistics.

This distinction will perhaps become clearer if we trace the thought process of a mathematician encountering her first craps game:
- If this mathematician were a probabilist, she would see the dice and think ``Six-sided dice? Presumably each face of the dice is equally likely to land face up. NowÂ _assuming_Â that each face comes up with probability 1/6, I can figure out what my chances of crapping out are.''
- If instead a statistician wandered by, she would see the dice and think ``Those dice may look OK, but how do IÂ _know_Â that they are not loaded? I'll watch a while, and keep track of how often each number comes up. Then I can decide if my observations are consistent with the assumption of equal-probability faces. Once I'm confident enough that the dice are fair, I'll call a probabilist to tell me how to play.''

In summary, probability theory enables us to find the consequences of a given ideal world, while statistical theory enables us to to measure the extent to which our world is ideal.

Modern probability theory emerged from the dice tables of France in 1654. Chevalier de MÃ©rÃ©, a French nobleman, wondered whether the player or the house had the advantage in a variation of the following betting game.[6.1](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/footnode.html#foot389)Â In the basic version, the player rolls four dice, and wins provided none of them are a six. The house collects on the even money bet if at least one six appears.Â Â 

De MÃ©rÃ© brought this problem to attention of the French mathematicians Blaise Pascal and Pierre de Fermat, most famous as the source of Fermat's Last Theorem. Together, these men worked out the basics of probability theory, along the way establishing that the house wins the basic version with probabilityÂ ![$p = 1 - (5/6)^4 \approx 0.517$](https://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/img12.gif), where the probabilityÂ _p_Â = 0.5 would denote a fair game where the house wins exactly half the time.Â Â Â Â The jai-alai world of our Monte Carlo simulation assumes that we decide the outcome of a point between two teams by flipping a suitably biased coin. If this world were reality, our simulation will compute the correct probability of each possible betting outcome. But all players are not created equal, of course. By doing a statistical study of the outcome of all the matches involving a particular player, we can determine an appropriate amount to bias the coin.

But such computations only make sense if our simulated jai-alai world is a model consistent with the real world. John von Neuman once said that ``the valuation of a poker hand can be sheer mathematics.'' We have to reduce our evaluation of a pelotari to sheer mathematics.



## Ref